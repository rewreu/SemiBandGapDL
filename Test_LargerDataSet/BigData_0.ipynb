{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Note\n",
    "This one is based on file Turot_0.ipynb, it enlarges the total data from 1000+ to 8000+. The sacrifice is training data is not semiconductor anymore. The data used in Turot_0 will be used as test data set. \n",
    "\n",
    "length of 3 elem data is  7293\n",
    "\n",
    "length of 2 elem data is  1230\n",
    "\n",
    "This is just for setup, the real test has been done at HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Save and load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "def loadFromPickle(pickle_file):\n",
    "    #pickle_file = 'SemiDataBase.pickle'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      save = pickle.load(f)\n",
    "      database= save['database']\n",
    "      del save  # hint to help gc free up memory\n",
    "    return database\n",
    "\n",
    "def saveTopickle(pickle_file_name,database):\n",
    " try:\n",
    "  f = open(pickle_file_name, 'wb')\n",
    "  save = {\n",
    "    'database':database,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    " except Exception as e:\n",
    "  print('Unable to save data to', pickle_file_name, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved Data and peak at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is: 1530\n",
      "icsd_ids >>>>>>>>>>>>>>>>>>>>> [41898]\n",
      "energy >>>>>>>>>>>>>>>>>>>>> -34.22314566\n",
      "elasticity >>>>>>>>>>>>>>>>>>>>> None\n",
      "unit_cell_formula >>>>>>>>>>>>>>>>>>>>> {u'S': 4.0, u'Ba': 1.0, u'Ag': 2.0, u'Sn': 1.0}\n",
      "oxide_type >>>>>>>>>>>>>>>>>>>>> None\n",
      "hubbards >>>>>>>>>>>>>>>>>>>>> {}\n",
      "task_ids >>>>>>>>>>>>>>>>>>>>> [u'mp-702596', u'mp-682621', u'mp-667121', u'mp-555166']\n",
      "band_gap >>>>>>>>>>>>>>>>>>>>> 0.3603\n",
      "e_above_hull >>>>>>>>>>>>>>>>>>>>> 0\n",
      "nsites >>>>>>>>>>>>>>>>>>>>> 8\n",
      "icsd_id >>>>>>>>>>>>>>>>>>>>> 41898\n",
      "elements >>>>>>>>>>>>>>>>>>>>> [u'Ag', u'Ba', u'S', u'Sn']\n",
      "tags >>>>>>>>>>>>>>>>>>>>> [u'Disilver barium tetrathiostannate(IV)']\n",
      "pretty_formula >>>>>>>>>>>>>>>>>>>>> BaAg2SnS4\n",
      "volume >>>>>>>>>>>>>>>>>>>>> 208.04569394\n",
      "total_magnetization >>>>>>>>>>>>>>>>>>>>> 0.0\n",
      "is_hubbard >>>>>>>>>>>>>>>>>>>>> False\n",
      "formation_energy_per_atom >>>>>>>>>>>>>>>>>>>>> -1.09570473828\n",
      "nelements >>>>>>>>>>>>>>>>>>>>> 4\n",
      "density >>>>>>>>>>>>>>>>>>>>> 4.7892306528\n",
      "is_compatible >>>>>>>>>>>>>>>>>>>>> True\n",
      "material_id >>>>>>>>>>>>>>>>>>>>> mp-555166\n",
      "energy_per_atom >>>>>>>>>>>>>>>>>>>>> -4.2778932075\n",
      "full_formula >>>>>>>>>>>>>>>>>>>>> Ba1Ag2Sn1S4\n"
     ]
    }
   ],
   "source": [
    "test=[]\n",
    "test=loadFromPickle('SemiDataBase.pickle')\n",
    "print \"length of data is: \"+str(len(test))\n",
    "for key in test[11]:\n",
    "    if key not in ['cif','spacegroup']:\n",
    "        print key,\">>>>>>>>>>>>>>>>>>>>>\",test[11][key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymatgen import MPRester, periodic_table\n",
    "from pymatgen import Composition, Element\n",
    "import itertools\n",
    "#########################fucntion to display data set in a periodic table format\n",
    "def displayInPeriodicTable(database,showElementsTable=True):\n",
    "    list2=[]\n",
    "    w, h = 18, 9;\n",
    "    Matrix = [['**' for x in range(w)] for y in range(h)] \n",
    "    Matrix2 = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "    for data in database:\n",
    "        for elem in data[\"elements\"]:\n",
    "    #         elem.row()\n",
    "            if elem not in list2:\n",
    "                list2.append(elem)\n",
    "                Matrix[Element(elem).row-1][Element(elem).group-1]=elem\n",
    "    for data in database:\n",
    "        for elem in data[\"elements\"]:          \n",
    "                Matrix2[Element(elem).row-1][Element(elem).group-1]=Matrix2[Element(elem).row-1][Element(elem).group-1]+1\n",
    "    if showElementsTable:\n",
    "        print \"elements appear in the dataset\"\n",
    "        print \"#\"*94\n",
    "        for row in range(h): \n",
    "            print \"#\",\n",
    "            for col in range(w):\n",
    "                print '%4s' % Matrix[row][col],\n",
    "            print \" #\",\n",
    "            print\n",
    "        print \"#\"*94\n",
    "    print \"Count of the elements appearance\"\n",
    "    print \"#\"*94\n",
    "    for row in range(h): \n",
    "        print \"#\",\n",
    "        for col in range(w):\n",
    "            print '%4d' % Matrix2[row][col],\n",
    "        print \" #\",\n",
    "        print\n",
    "    print \"#\"*94\n",
    "#########################fucntion to display data set in a periodic table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements appear in the dataset\n",
      "##############################################################################################\n",
      "#    H   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "#   Li   Be   **   **   **   **   **   **   **   **   **   **    B    C    N    O    F   **  #\n",
      "#   Na   Mg   **   **   **   **   **   **   **   **   **   **   Al   Si    P    S   Cl   **  #\n",
      "#    K   Ca   Sc   Ti    V   Cr   Mn   Fe   Co   Ni   Cu   Zn   Ga   Ge   As   Se   Br   **  #\n",
      "#   Rb   Sr    Y   Zr   Nb   Mo   Tc   Ru   Rh   Pd   Ag   Cd   In   Sn   Sb   Te    I   **  #\n",
      "#   Cs   Ba   **   Hf   Ta    W   Re   Os   Ir   Pt   Au   Hg   Tl   Pb   Bi   **   **   **  #\n",
      "#   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "#   **   **   La   Ce   Pr   Nd   **   Sm   Eu   Gd   Tb   Dy   Ho   Er   Tm   Yb   Lu   **  #\n",
      "#   **   **   **   Th   **    U   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "##############################################################################################\n",
      "Count of the elements appearance\n",
      "##############################################################################################\n",
      "#  284    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#  409   82    0    0    0    0    0    0    0    0    0    0  266  118  384 2669  846    0  #\n",
      "#  487  252    0    0    0    0    0    0    0    0    0    0  298  258  552  658  607    0  #\n",
      "#  577  280  126  172  199  173  250  212  186  210  224  201  249  301  304  462  351    0  #\n",
      "#  458  306  174  148  192  136   50  133  147  200  193  188  227  292  334  380  321    0  #\n",
      "#  464  369    0   90  156  116  117   69   99  180  230  152  250  163  154    0    0    0  #\n",
      "#    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#    0    0  189   91  131  131    0  141  121  195   93  110  137  129  124  101  146    0  #\n",
      "#    0    0    0   67    0  118    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "##############################################################################################\n",
      "in test data set\n",
      "Count of the elements appearance\n",
      "##############################################################################################\n",
      "#   38    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#   70    5    0    0    0    0    0    0    0    0    0    0  103   12   39  523   33    0  #\n",
      "#   90   38    0    0    0    0    0    0    0    0    0    0   28   48  168  343   43    0  #\n",
      "#  175   56   14   34   40   14   25   15   22   17   98   48   64   73  101  295   42    0  #\n",
      "#   87   48   12   10   45   32    2   13    4   15   61   68   68   67  105  148   71    0  #\n",
      "#   99  107    0    6   46    5    5    3    7   11    7   37   79   50  126    0    0    0  #\n",
      "#    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#    0    0   39   14   20   16    0   25   11   12   12   13   10    9    3    8    6    0  #\n",
      "#    0    0    0   13    0    6    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "##############################################################################################\n"
     ]
    }
   ],
   "source": [
    "train=loadFromPickle('FullRawData3Elem2Elem_dropRepeat')\n",
    "displayInPeriodicTable(train)\n",
    "print \"in test data set\"\n",
    "test=loadFromPickle('SemiDataBase.pickle')\n",
    "displayInPeriodicTable(test,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manipulate the data(make into traning data set format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will make three data sets, PTFeatures will be vectors with (9x18) dimensions represents the elements in periodic table. bandgaps will contains all the bandgap info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dimensions is (7299, 162)\n",
      "train label dimensions is (7299, 1)\n",
      "test data dimensions is (1530, 162)\n",
      "test label dimensions is (1530, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def PeriodicTableVectorize(composition):\n",
    "    vector = np.zeros((9,18)) # size of periodic table\n",
    "    for element in composition:\n",
    "        fraction = composition.get_atomic_fraction(element)\n",
    "        vector[element.row-1,element.group-1] = fraction\n",
    "    return vector\n",
    "\n",
    "def formatData(database):\n",
    "    materials=[]\n",
    "    bandgaps=[]\n",
    "    PTFeatures = []\n",
    "    for item in database:\n",
    "        materials.append(item[\"full_formula\"])\n",
    "        bandgaps.append(item[\"band_gap\"])\n",
    "    for item in materials:\n",
    "       material = Composition(item)\n",
    "       PTFeatures.append(PeriodicTableVectorize(material)) #create features from chemical formula\n",
    "    return materials,PTFeatures,bandgaps\n",
    "\n",
    "def reformat1D(dataset, labels):\n",
    "    dataset=np.asarray(dataset)\n",
    "    labels=np.asarray(labels)\n",
    "    dataset = dataset.reshape((-1, dataset.shape[1] * dataset.shape[2])).astype(np.float32)\n",
    "    labels = (labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_material,train_vec,train_bandgaps=formatData(train)\n",
    "test_material,test_vec,test_bandgaps=formatData(test)\n",
    "train_1d,train_label=reformat1D(train_vec,train_bandgaps)\n",
    "test_1d,test_label=reformat1D(test_vec,test_bandgaps)\n",
    "print \"train data dimensions is\", train_1d.shape\n",
    "print \"train label dimensions is\", train_label.shape\n",
    "print \"test data dimensions is\", test_1d.shape\n",
    "print \"test label dimensions is\", test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's concatenate train with csv file data\n",
    "the real data is not using from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainFile = open(\"bandgapDFT.csv\",\"r\").readlines()\n",
    "def ReadDataFromCSV(Filename=\"bandgapDFT.csv\"):\n",
    "    bandgaps = []\n",
    "    naiveFeatures = []\n",
    "    trainFile = open(Filename,\"r\").readlines()\n",
    "    for line in trainFile:\n",
    "           split = str.split(line, ',')\n",
    "           material = Composition(split[0])\n",
    "           naiveFeatures.append(PeriodicTableVectorize(material)) #create features from chemical formula\n",
    "           bandgaps.append(float(split[1])) #store numerical values of band gaps\n",
    "    return naiveFeatures,bandgaps\n",
    "\n",
    "### a function to limit the bandgat between 0 and 10\n",
    "def ReadDataFromCSV_Trim(Filename=\"bandgapDFT.csv\"):\n",
    "    bandgaps = []\n",
    "    naiveFeatures = []\n",
    "    materials=[]\n",
    "    trainFile = open(Filename,\"r\").readlines()\n",
    "    for line in trainFile:\n",
    "           split = str.split(line, ',')\n",
    "           if float(split[1])>0.1 and float(split[1])<10:\n",
    "               material = Composition(split[0])\n",
    "               materials.append(split[0])\n",
    "               naiveFeatures.append(PeriodicTableVectorize(material)) #create features from chemical formula\n",
    "               bandgaps.append(float(split[1])) #store numerical values of band gaps\n",
    "    return naiveFeatures,bandgaps,materials\n",
    "    \n",
    "\n",
    "# train_csv,label_csv,materials_csv=ReadDataFromCSV_Trim()\n",
    "# train_1d_csv,lebel_1d_csv=reformat1D(train_csv,label_csv)\n",
    "# print \"train csv data dimensions is\", train_1d_csv.shape\n",
    "# print \"label csv data dimensions is\", lebel_1d_csv.shape\n",
    "            \n",
    "#tmp1=np.concatenate((train_1d,train_1d_csv ), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot everyting in histgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGHCAYAAAD/QltcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHBDb8d2cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f471dd14dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of Train datadata is 1.97 eV\n",
      "median of Train data data is 1.69 eV\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZXi/wOo33ipk5p+2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f471cec2290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of Test datadata is 1.85 eV\n",
      "median of Test data data is 1.59 eV\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import plotly.plotly as py\n",
    "def HistBandgap(bandgap,label=\"labels\"):\n",
    "    bins = np.linspace(0, 9, 200)\n",
    "    plt.hist(bandgap,bins,alpha=0.5)\n",
    "    plt.title(\"Bandgap Histogram of \"+label)\n",
    "    plt.xlabel(\"BandGap(eV)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    #plt.text(3, bandgap.max(), \"mean of data is \"+str(np.around(np.mean(bandgap),decimals=2))+\" eV\")\n",
    "    #plt.text(3, 80, \"median of data is \"+str(np.around(np.median(bandgap),decimals=2))+\" eV\")\n",
    "    plt.show()\n",
    "    print \"mean of \" +label+\"data is \"+str(np.around(np.mean(bandgap),decimals=2))+\" eV\"\n",
    "    print \"median of \" +label+\" data is \"+str(np.around(np.median(bandgap),decimals=2))+\" eV\"\n",
    "HistBandgap(train_label,\"Train data\")\n",
    "HistBandgap(test_label,\"Test data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randamize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "# train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "# test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "# valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "# shuffle  the data\n",
    "train_1d,train_label=randomize(train_1d,train_label)\n",
    "test_1d,test_label=randomize(test_1d,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save machine learning data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'VectorRep_Bandgap.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_1d':train_1d,\n",
    "    'train_label':train_label,\n",
    "    'test_1d':test_1d,\n",
    "    'test_label':test_label,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load machine learning data to pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'VectorRep_Bandgap.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_1d = save['train_1d']\n",
    "  train_label = save['train_label']\n",
    "  test_1d = save['test_1d']\n",
    "  test_label = save['test_label']  \n",
    "  del save  # hint to help gc free up memory\n",
    "\n",
    "train_dataset=train_1d\n",
    "train_labels=train_label\n",
    "test_dataset=test_1d\n",
    "test_labels=test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine learning\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of always guessing the average band gap of train data is: 1.38 eV\n",
      "The MAE of always guessing the average band gap of test data is: 1.086 eV\n"
     ]
    }
   ],
   "source": [
    "train_labels=train_label\n",
    "baselineError = np.mean(abs(np.mean(train_labels) - train_labels))\n",
    "print(\"The MAE of always guessing the average band gap of train data is: \" + str(round(baselineError, 3)) + \" eV\")\n",
    "test_label\n",
    "baselineError = np.mean(abs(np.mean(test_label) - test_label))\n",
    "print(\"The MAE of always guessing the average band gap of test data is: \" + str(round(baselineError, 3)) + \" eV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the linear ridge regression band gap model using the train set is: 0.893 eV\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAF5CAYAAADUL/MIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ZxwmJmZWeH+BwE1FhXBNZx5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4717267d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the linear ridge regression band gap model using the test set is: 0.7 eV\n"
     ]
    }
   ],
   "source": [
    "# Train linear ridge regression model using naive feature set\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn import linear_model, cross_validation, metrics, ensemble\n",
    "\n",
    "# train_dataset=Fulldata[0:1300]\n",
    "# train_labels=labels[0:1300]\n",
    "# test_dataset=Fulldata[1300:1531]\n",
    "# test_labels=labels[1300:1531]\n",
    "train_dataset=train_1d\n",
    "train_labels=train_label\n",
    "test_dataset=test_1d\n",
    "test_labels=test_label\n",
    "\n",
    "num_samples=train_dataset.shape[0]\n",
    "#this won't work if num_samples are too small, if num_samples is too small, all Y is 0( the first number type), so it has to be large engouh\n",
    "\n",
    "# (samples, width, height) = train_dataset.shape\n",
    "# X = np.reshape(train_dataset,(samples,width*height))[0:num_samples]\n",
    "# Y = train_labels[0:num_samples]\n",
    "\n",
    "\n",
    "# X = np.concatenate((train_dataset,test_dataset),axis=0)\n",
    "# Y = np.concatenate((train_labels,test_labels),axis=0)\n",
    "\n",
    "X=train_dataset\n",
    "Y=train_labels\n",
    "\n",
    "Xt=test_dataset\n",
    "Yt=test_labels\n",
    "\n",
    "#alpha is a tuning parameter affecting how regression deals with collinear inputs\n",
    "linear = linear_model.Ridge(alpha = 0.6)  \n",
    "\n",
    "cv = cross_validation.ShuffleSplit(len(Y),n_iter=10, test_size=0.1, random_state=0)\n",
    "\n",
    "scores = cross_validation.cross_val_score(linear, X,Y, cv=cv, scoring='mean_absolute_error')\n",
    "\n",
    "print(\"The MAE of the linear ridge regression band gap model using the train set is: \"+ str(round(abs(np.mean(scores)), 3)) + \" eV\")\n",
    "############# plot it##########################################\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "# predicted = cross_val_predict(linear, X, Y, cv=10)\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(Y, predicted)\n",
    "# ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=2)\n",
    "# ax.set_xlabel('Measured')\n",
    "# ax.set_ylabel('Predicted')\n",
    "# plt.show()\n",
    "############# plot it##########################################\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(linear, Xt, Yt, cv=10)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Yt, predicted)\n",
    "ax.plot([Yt.min(), Yt.max()], [Yt.min(), Yt.max()], 'k--', lw=2)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "cv = cross_validation.ShuffleSplit(len(Yt),n_iter=10, test_size=0.1, random_state=0)\n",
    "scores = cross_validation.cross_val_score(linear, Xt,Yt, cv=cv, scoring='mean_absolute_error')\n",
    "print(\"The MAE of the linear ridge regression band gap model using the test set is: \"+ str(round(abs(np.mean(scores)), 3)) + \" eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "### without hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530\n",
      "7299\n"
     ]
    }
   ],
   "source": [
    "print len(test_dataset)\n",
    "print len(train_dataset)\n",
    "Fulldata=train_dataset\n",
    "labels=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7299, 162)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (6500, 162), (6500, 1))\n",
      "('Validation set', (799, 162), (799, 1))\n",
      "('Test set', (1530, 162), (1530, 1))\n"
     ]
    }
   ],
   "source": [
    "# image_size = 28\n",
    "num_labels = 1\n",
    "train_end=6500\n",
    "\n",
    "train_dataset=Fulldata[:train_end]\n",
    "train_labels=labels[:train_end]\n",
    "valid_dataset=Fulldata[train_end:]\n",
    "valid_labels=labels[train_end:]\n",
    "# test_dataset\n",
    "# test_labels\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, Fulldata.shape[1])).astype(np.float32)\n",
    "  labels = labels\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 2.201866\n",
      "Validation Loss: 1.892077\n",
      "Loss at step 2000: 0.872147\n",
      "Validation Loss: 0.833968\n",
      "Loss at step 4000: 0.862680\n",
      "Validation Loss: 0.827784\n",
      "Loss at step 6000: 0.859784\n",
      "Validation Loss: 0.827682\n",
      "Loss at step 8000: 0.858745\n",
      "Validation Loss: 0.827643\n",
      "Loss at step 10000: 0.858270\n",
      "Validation Loss: 0.827583\n",
      "Loss at step 12000: 0.858045\n",
      "Validation Loss: 0.827396\n",
      "Loss at step 14000: 0.857936\n",
      "Validation Loss: 0.827231\n",
      "Loss at step 16000: 0.857900\n",
      "Validation Loss: 0.827303\n",
      "Loss at step 18000: 0.857889\n",
      "Validation Loss: 0.827460\n",
      "Test Loss: 0.730812\n"
     ]
    }
   ],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "\n",
    "train_subset = train_end\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  weights = tf.Variable(tf.truncated_normal([Fulldata.shape[1] , num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = logits  \n",
    "\n",
    "  valid_prediction = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  test_prediction = tf.matmul(tf_test_dataset, weights) + biases\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 20000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 2000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with one hidden layer, train with batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 8.342926\n",
      "Validation Loss: 100.371498\n",
      "Loss at step 1000: 0.814454\n",
      "Validation Loss: 0.945581\n",
      "Loss at step 2000: 0.772067\n",
      "Validation Loss: 0.845478\n",
      "Loss at step 3000: 0.772132\n",
      "Validation Loss: 0.763398\n",
      "Loss at step 4000: 0.716359\n",
      "Validation Loss: 0.763175\n",
      "Loss at step 5000: 0.748424\n",
      "Validation Loss: 0.810828\n",
      "Loss at step 6000: 0.609731\n",
      "Validation Loss: 0.723730\n",
      "Loss at step 7000: 0.507604\n",
      "Validation Loss: 0.623963\n",
      "Loss at step 8000: 0.671138\n",
      "Validation Loss: 0.690130\n",
      "Loss at step 9000: 0.500061\n",
      "Validation Loss: 0.739839\n",
      "Test Loss: 0.652243\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "train_subset = train_end\n",
    "#batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] , num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = logits  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add regulation to previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 71.452751\n",
      "Validation Loss: 63.694595\n",
      "Loss at step 1000: 24.364183\n",
      "Validation Loss: 0.789157\n",
      "Loss at step 2000: 9.542454\n",
      "Validation Loss: 0.922216\n",
      "Loss at step 3000: 4.118528\n",
      "Validation Loss: 0.830241\n",
      "Loss at step 4000: 2.039590\n",
      "Validation Loss: 0.918599\n",
      "Loss at step 5000: 1.309195\n",
      "Validation Loss: 1.030370\n",
      "Loss at step 6000: 0.846725\n",
      "Validation Loss: 0.717876\n",
      "Loss at step 7000: 0.848893\n",
      "Validation Loss: 0.666907\n",
      "Loss at step 8000: 0.914854\n",
      "Validation Loss: 0.810108\n",
      "Loss at step 9000: 0.774651\n",
      "Validation Loss: 0.806920\n",
      "Test Loss: 0.646437\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "#train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] , num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  train_prediction = logits  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout added to previous test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 73.645538\n",
      "Validation Loss: 16.276495\n",
      "Loss at step 1000: 24.098148\n",
      "Validation Loss: 0.686216\n",
      "Loss at step 2000: 9.174386\n",
      "Validation Loss: 0.799104\n",
      "Loss at step 3000: 3.764966\n",
      "Validation Loss: 0.740538\n",
      "Loss at step 4000: 1.878308\n",
      "Validation Loss: 0.751335\n",
      "Loss at step 5000: 1.016863\n",
      "Validation Loss: 0.606579\n",
      "Loss at step 6000: 0.864439\n",
      "Validation Loss: 0.675523\n",
      "Loss at step 7000: 0.684641\n",
      "Validation Loss: 0.720152\n",
      "Loss at step 8000: 0.670896\n",
      "Validation Loss: 0.604405\n",
      "Loss at step 9000: 0.830222\n",
      "Validation Loss: 0.630259\n",
      "Test Loss: 0.617904\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "#batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] , num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################\n",
    "  layer_1_train= tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  train_prediction = tf.matmul(layer_1_train, weights_2) + biases_2  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below try to use different initial value(stddev) for weight to see if accuracy can be improved,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 2.629410\n",
      "Validation Loss: 1.136134\n",
      "Loss at step 1000: 0.861606\n",
      "Validation Loss: 0.610521\n",
      "Loss at step 2000: 0.632770\n",
      "Validation Loss: 0.590188\n",
      "Loss at step 3000: 0.758573\n",
      "Validation Loss: 0.798777\n",
      "Loss at step 4000: 0.566694\n",
      "Validation Loss: 0.672346\n",
      "Loss at step 5000: 0.764544\n",
      "Validation Loss: 0.646416\n",
      "Loss at step 6000: 0.625068\n",
      "Validation Loss: 0.651513\n",
      "Loss at step 7000: 0.557081\n",
      "Validation Loss: 0.697748\n",
      "Loss at step 8000: 0.716716\n",
      "Validation Loss: 0.643046\n",
      "Loss at step 9000: 0.632172\n",
      "Validation Loss: 0.770132\n",
      "Test Loss: 0.592279\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] \n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train= tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  train_prediction = tf.matmul(layer_1_train, weights_2) + biases_2  \n",
    "\n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 3.125145\n",
      "Validation Loss: 1.431295\n",
      "Loss at step 1000: 1.388849\n",
      "Validation Loss: 0.774048\n",
      "Loss at step 2000: 0.939148\n",
      "Validation Loss: 0.716816\n",
      "Loss at step 3000: 1.014927\n",
      "Validation Loss: 0.848569\n",
      "Loss at step 4000: 0.776024\n",
      "Validation Loss: 0.737681\n",
      "Loss at step 5000: 1.207989\n",
      "Validation Loss: 1.322314\n",
      "Loss at step 6000: 0.715510\n",
      "Validation Loss: 0.683966\n",
      "Loss at step 7000: 0.934632\n",
      "Validation Loss: 0.835293\n",
      "Loss at step 8000: 0.830456\n",
      "Validation Loss: 0.799800\n",
      "Loss at step 9000: 0.828547\n",
      "Validation Loss: 0.733529\n",
      "Test Loss: 0.643807\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "num_hidden_nodes2=512\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] \n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2=tf.Variable(tf.truncated_normal([num_hidden_nodes, num_hidden_nodes2],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_2=tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "  \n",
    "  weights_o =  tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes))))  \n",
    "  biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  layer_2=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_1,weights_2)+biases_2),0.75)\n",
    "  \n",
    "  logits = tf.matmul(layer_2, weights_o) + biases_o\n",
    "  \n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_o)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train=tf.nn.relu(tf.matmul(tf_train_dataset,weights_1)+biases_1)\n",
    "  layer_2_train=tf.nn.relu(tf.matmul(layer_1_train,weights_2)+biases_2)\n",
    "  train_prediction = tf.matmul(layer_2_train, weights_o) + biases_o  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  layer_2_valid = tf.nn.relu(tf.matmul(layer_1_valid, weights_2) + biases_2)  \n",
    "  valid_prediction = tf.matmul(layer_2_valid, weights_o) + biases_o\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  layer_2_test = tf.nn.relu(tf.matmul(layer_1_test, weights_2) + biases_2)\n",
    "  test_prediction = tf.matmul(layer_2_test, weights_o) + biases_o\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result here is not good due to small number of steps, a larger training step test is done at WSU grid which yields a big score at test loss of 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 1.812679\n",
      "Validation Loss: 1.182081\n",
      "Loss at step 100: 1.104610\n",
      "Validation Loss: 0.849097\n",
      "Loss at step 200: 0.899612\n",
      "Validation Loss: 0.827634\n",
      "Loss at step 300: 0.723385\n",
      "Validation Loss: 0.710807\n",
      "Loss at step 400: 0.641590\n",
      "Validation Loss: 0.855809\n",
      "Loss at step 500: 0.610064\n",
      "Validation Loss: 0.730401\n",
      "Loss at step 600: 0.538624\n",
      "Validation Loss: 0.654029\n",
      "Loss at step 700: 0.593479\n",
      "Validation Loss: 0.690829\n",
      "Loss at step 800: 0.520996\n",
      "Validation Loss: 0.654888\n",
      "Loss at step 900: 0.595485\n",
      "Validation Loss: 0.622961\n",
      "Test Loss: 0.853504\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "num_hidden_nodes2=512\n",
    "num_hidden_nodes3=128\n",
    "num_labels = 1\n",
    "beta=1e-3\n",
    "\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] \n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2=tf.Variable(tf.truncated_normal([num_hidden_nodes, num_hidden_nodes2],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_2=tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    \n",
    "  weights_3=tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes2))))\n",
    "  biases_3=tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    \n",
    "  \n",
    "  weights_o =  tf.Variable(tf.truncated_normal([num_hidden_nodes3, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes3))))  \n",
    "  biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  layer_2=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_1,weights_2)+biases_2),keep_prob=0.8)\n",
    "  layer_3=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_2,weights_3)+biases_3),keep_prob=0.8)\n",
    "  \n",
    "  logits = tf.matmul(layer_3, weights_o) + biases_o\n",
    "  \n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "  +beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_o)\n",
    "  +tf.nn.l2_loss(weights_2)+tf.nn.l2_loss(weights_3))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train=tf.nn.relu(tf.matmul(tf_train_dataset,weights_1)+biases_1)\n",
    "  layer_2_train=tf.nn.relu(tf.matmul(layer_1_train,weights_2)+biases_2)\n",
    "  layer_3_train=tf.nn.relu(tf.matmul(layer_2_train,weights_3)+biases_3)\n",
    "  train_prediction = tf.matmul(layer_3_train, weights_o) + biases_o\n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  layer_2_valid = tf.nn.relu(tf.matmul(layer_1_valid, weights_2) + biases_2)\n",
    "  layer_3_valid = tf.nn.relu(tf.matmul(layer_2_valid, weights_3) + biases_3)\n",
    "  valid_prediction = tf.matmul(layer_3_valid, weights_o) + biases_o\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  layer_2_test = tf.nn.relu(tf.matmul(layer_1_test, weights_2) + biases_2)\n",
    "  layer_3_test = tf.nn.relu(tf.matmul(layer_2_test, weights_3) + biases_3)\n",
    "  test_prediction = tf.matmul(layer_3_test, weights_o) + biases_o\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 1000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
