{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# old code from online instructions at https://contact.citrine.io/blog/2015/3/3/machine-learning-mat-sci-1\n",
    "# doesn't work, seems that developer at material project delete the API for make all combinations from periodic_table\n",
    "# from pymatgen import MPRester, periodic_table\n",
    "# import itertools\n",
    "\n",
    "# API_KEY = 'IJeQxmCAHlrKGW4T' # You have to register with Materials Project to receive an API\n",
    "\n",
    "# # There are 103 elements in pymatgen's list, giving C(103, 2) = 5253 binary systems\n",
    "# allBinaries = itertools.combinations(periodic_table.Specie, 2) # Create list of all binary systems\n",
    "\n",
    "# with MPRester(API_KEY) as m:\n",
    "#     for system in allBinaries:\n",
    "#         results = m.get_data(system[0] + '-' + system[1], data_type='vasp') # Download DFT data for each binary system\n",
    "#         for material in results: # We will receive many compounds within each binary system\n",
    "#             if material['e_above_hull'] < 1e-6: # Check if this compound is thermodynamically stable\n",
    "#                 print(material['pretty_formula'] + ',' + str(material['band_gap'])) # Output band gap csv to the screen      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data below comes from following database\n",
    "http://bg.imet-db.ru/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2  # the lib that handles the url stuff\n",
    "data = urllib2.urlopen(\"http://bg.imet-db.ru/api/?mode=system&format=json\") # it's a file like object and works just like a file\n",
    "for line in data: # files are iterable\n",
    "    Temp=eval(line)\n",
    "    #print line\n",
    "# typo \")-Cr-Li-Te\"\n",
    "Temp[0]=\"Cr-Li-Te\"\n",
    "# typo \"0-Ga-Sn-Zn\"\n",
    "Temp[1]=\"Ga-Sn-Zn\"\n",
    "# typo 'Mn-S1-Sb-Sm'\n",
    "Temp[1772]=\"Mn-S-Sb-Sm\"\n",
    "# this one is not in material project\n",
    "Temp.remove(\"As-Pb-S-Sb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somedata they are connected with ',' instead of '-', below is the code to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,elem in enumerate(Temp):\n",
    "    if ',' in elem: \n",
    "#        print elem\n",
    "#        print elem.replace(',','-')\n",
    "        Temp[i]=elem.replace(',','-')\n",
    "# another mistake in the database to fix\n",
    "    if elem=='Bi-e-K-Rb': Temp[i]='Bi-Er-K-Rb' #\n",
    "    if elem=='Cu-Se-Si-Zm': Temp[i]='Cu-Se-Si-Sm' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the index data to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'SemicoductorSystems.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'Namesys':Temp,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the index data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'SemicoductorSystems.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  Temp = save['Namesys']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowload the data and Save to pickle file \n",
    "Now lets download some data from material project data base at \n",
    "https://materialsproject.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pymatgen import MPRester, periodic_table\n",
    "import itertools\n",
    "\n",
    "API_KEY = 'IJeQxmCAHlrKGW4T' # You have to register with Materials Project to receive an API\n",
    "#partial=10\n",
    "partial=len(Temp)\n",
    "breakpoint=1162\n",
    "Temp2=Temp[breakpoint:partial]\n",
    "#database=[]\n",
    "\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "with MPRester(API_KEY) as m:\n",
    "#    results = m.get_data(Temp[190], data_type='vasp')\n",
    "    for system in Temp2:\n",
    "        results = m.get_data(system, data_type='vasp') # Download DFT data for each binary system\n",
    "        if results !=[]:\n",
    "          for material in results: # We will receive many compounds within each binary system\n",
    "            if (material['band_gap']>0) and (material['e_above_hull'] < 1e-6): # Check if this compound is thermodynamically stable\n",
    "                #print(material['pretty_formula'] + ',' + str(material['band_gap'])) # Output band gap csv to the screen \n",
    "                database.append(material)\n",
    "timecost=time.time()-start\n",
    "#write to SemiDataBase pickle file\n",
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'SemiDataBase.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'database':database,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'SemiDataBase.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  database= save['database']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a quick look at 11th item of data\n",
    "for key in database[11]:\n",
    "    print key,\">>>>>>>>>>>>>>>>>>>>>\",database[11][key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below gives an intuitive look at the elements distribution in periodic table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elements appear in the dataset\n",
      "##############################################################################################\n",
      "#    H   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "#   Li   Be   **   **   **   **   **   **   **   **   **   **    B    C    N    O    F   **  #\n",
      "#   Na   Mg   **   **   **   **   **   **   **   **   **   **   Al   Si    P    S   Cl   **  #\n",
      "#    K   Ca   Sc   Ti    V   Cr   Mn   Fe   Co   Ni   Cu   Zn   Ga   Ge   As   Se   Br   **  #\n",
      "#   Rb   Sr    Y   Zr   Nb   Mo   Tc   Ru   Rh   Pd   Ag   Cd   In   Sn   Sb   Te    I   **  #\n",
      "#   Cs   Ba   **   Hf   Ta    W   Re   Os   Ir   Pt   Au   Hg   Tl   Pb   Bi   **   **   **  #\n",
      "#   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "#   **   **   La   Ce   Pr   Nd   **   Sm   Eu   Gd   Tb   Dy   Ho   Er   Tm   Yb   Lu   **  #\n",
      "#   **   **   **   Th   **    U   **   **   **   **   **   **   **   **   **   **   **   **  #\n",
      "##############################################################################################\n",
      "Count of the elements appearance\n",
      "##############################################################################################\n",
      "#   38    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#   70    5    0    0    0    0    0    0    0    0    0    0  103   12   39  523   33    0  #\n",
      "#   90   38    0    0    0    0    0    0    0    0    0    0   28   48  168  343   43    0  #\n",
      "#  175   56   14   34   40   14   25   15   22   17   98   48   64   73  101  295   42    0  #\n",
      "#   87   48   12   10   45   32    2   13    4   15   61   68   68   67  105  148   71    0  #\n",
      "#   99  107    0    6   46    5    5    3    7   11    7   37   79   50  126    0    0    0  #\n",
      "#    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "#    0    0   39   14   20   16    0   25   11   12   12   13   10    9    3    8    6    0  #\n",
      "#    0    0    0   13    0    6    0    0    0    0    0    0    0    0    0    0    0    0  #\n",
      "##############################################################################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymatgen import MPRester, periodic_table\n",
    "from pymatgen import Composition, Element\n",
    "import itertools\n",
    "# list1=[1,2,3]\n",
    "# 4 in list1\n",
    "list2=[]\n",
    "# for ele in database[1][\"elements\"]:\n",
    "#     print ele\n",
    "#     print type(ele)\n",
    "#     list2.append(ele)\n",
    "\n",
    "# Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "\n",
    "# creat an matrix for periorod table\n",
    "\n",
    "w, h = 18, 9;\n",
    "Matrix = [['**' for x in range(w)] for y in range(h)] \n",
    "Matrix2 = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "for data in database:\n",
    "    for elem in data[\"elements\"]:\n",
    "#         elem.row()\n",
    "        if elem not in list2:\n",
    "            list2.append(elem)\n",
    "            Matrix[Element(elem).row-1][Element(elem).group-1]=elem\n",
    "for data in database:\n",
    "    for elem in data[\"elements\"]:          \n",
    "            Matrix2[Element(elem).row-1][Element(elem).group-1]=Matrix2[Element(elem).row-1][Element(elem).group-1]+1\n",
    "\n",
    "print \"elements appear in the dataset\"\n",
    "print \"#\"*94\n",
    "for row in range(h): \n",
    "    print \"#\",\n",
    "    for col in range(w):\n",
    "        print '%4s' % Matrix[row][col],\n",
    "    print \" #\",\n",
    "    print\n",
    "print \"#\"*94\n",
    "print \"Count of the elements appearance\"\n",
    "print \"#\"*94\n",
    "for row in range(h): \n",
    "    print \"#\",\n",
    "    for col in range(w):\n",
    "        print '%4d' % Matrix2[row][col],\n",
    "    print \" #\",\n",
    "    print\n",
    "print \"#\"*94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manipulate the data(make into traning data set format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will make three data sets, PTFeatures will be vectors with (9x18) dimensions represents the elements in periodic table. bandgaps will contains all the bandgap info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions is (1530, 9, 18)\n",
      "label dimensions is (1530,)\n"
     ]
    }
   ],
   "source": [
    "materials = []\n",
    "bandgaps = []\n",
    "PTFeatures = []\n",
    "\n",
    "for item in database:\n",
    "    materials.append(item[\"full_formula\"])\n",
    "    bandgaps.append(item[\"band_gap\"])\n",
    "\n",
    "def PeriodicTableVectorize(composition):\n",
    "       vector = zeros((9,18)) # size of periodic table\n",
    "       for element in composition:\n",
    "               fraction = composition.get_atomic_fraction(element)\n",
    "               vector[element.row-1,element.group-1] = fraction\n",
    "       return(vector)\n",
    "\n",
    "for item in materials:\n",
    "       material = Composition(item)\n",
    "       PTFeatures.append(PeriodicTableVectorize(material)) #create features from chemical formula\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "Fulldata=np.asarray(PTFeatures)\n",
    "print \"data dimensions is\", Fulldata.shape\n",
    "labels=np.asarray(bandgaps)\n",
    "print \"label dimensions is\", labels.shape\n",
    "# since the data it self is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd4VGX6//H3HUoKTaqAgoiiCwsoRMGKy6pYQcFGQEEE\n1BXFRdG1i+i6ftm1LJavuqsC6i+6i7quylcsWFiKNIWVIr2oEEEklJACeX5/nJlhMpmUmUwyk+Tz\nuq65ZE55zn0mSO55zn3uY845RERERCoqKd4BiIiISM2gpEJERERiQkmFiIiIxISSChEREYkJJRUi\nIiISE0oqREREJCaUVIiIiEhMKKkQERGRmFBSISIiIjGhpEKkhjCzCWZWGO84Ys3MCs3sgXjHISJl\nU1IhEiEzG+77RRf8yjKzWWZ2fhxDc75XwvInPmbWrIT1G83s3yGLIz4vM8sws1ujjVNEolM33gGI\nVFMOuB/YCBhwOHAtMMPMLnbOzYhfaAmtrAQh3LpU4ECExxkC/Br4a4T7iUgFKKkQid6Hzrkl/jdm\n9jKQBWQASipixDmXH+8YImVmac65nHjHIVLVdPlDJEacc7uA/YR8qzaz8WY2x8x2mFmOmS0ys8tC\n9/ddFphsZpeY2X/NLNfMvjWz88Jse4aZLTSz/Wa2xsyuDxeTmaX4xtxuZrvN7F9m1ja0TsHM2pvZ\nc2a2yhfjDjP7h5kdFTKe/9LPmWb2gm+7bDObamaHRfvZlSZMrA3N7Ckz2+D7jLLM7CMzO9G3/jPg\nIuCooMtT64P2b2lmL5nZNt/n942ZDQtz3GZm9qrv/H4xs1fMrLtvvGFB200xsz1m1tHMZpjZbuA1\n37ozzOxNM9vki3WzmT1hZikhx/KP0c7M3vf9eYuZ3eRb383MPjWzvb5LRBkx/phFYkIzFSLRa2Jm\nzfEuf7QCxgINgFdDthsLvIv3i6Y+MBj4h+8yyf+FbHsmMAh4Dtjj23e6mR3lnNsJYGZdgZnAT8AD\nQD1ggu99qKnA5cA04CvgLOADil9mOBk4BcgEvgc6ADcBn5lZF+dcbsj2zwC/AA8CxwFjgPZA3zAx\nhNPczCxkmVG+Lzov4H1GTwMrgebA6UBn4BvgEaAJcATwe9+4e8FLsoDPgWN8+28ErgCmmFkT59zT\nvu0MeB84Ce9n8R1wCd7nGfrZObx/S2cCs4HbAf8sxRVAmm+Mn4FewC2+2K4KGSMJ+D/gC+AOYCjw\ntJntA/6I9/fnLeBGYKqZzXXObSrH5yVSdZxzeumlVwQvYDhQGOaVA1wTZvvkkPd1gGXAxyHLC/Fm\nOjoELevmW35T0LJ3gH3AEUHLjgcKgINBy3r49v1LyHFeBg4CD5QUo29ZL9/+Q8Oc+1dAnaDl431j\nXlzGZ/dgCZ+d/3UQ+HeYzyU41l+AyWUc5z1gfZjlt/qOMTjk5zEHyAYa+JYN8h335pD9P/HtPyxo\n2Su+ZY+U9bP3LfsD3mzWkWHGuDNoWRPfz/kAcFnQ8uNCPxO99EqUly5/iETHAb8DzvG9hgKfAS+Z\n2aVFNnQuz/9n3yWCpnjfaHuGGfdj59zGoH3/C+wGOvr2TwLOBf7lnPshaLvv8L4pBzvfF+f/hix/\nGu/be0kx1vXdnbEe7xd4uDhfdM4dDHr/v3i/FC8Ms20oBwzk0GcX/Ao32xJqF9DLzNqUY9tQFwDb\nnHNvBILxzmMy0BBvJge8zy4f+HvI/s8S8tkFeT50Qcjnmuab2ZqHNyvRI8wYLwXtm403Q7LPOfdW\n0PLVeJ9BxxLiEIkbXf4Qid5CV7RQ8w1gCfCMmb3vnDvgW34xcC9wIpActH+4nhJbwiz7BS8RAWiJ\nN52+Jsx23+H90vQ7yneMDSHbrQ3d0XdZ4B68O1iO4NAvTof3jTmYCx3DObfPzLb6jlkes53vck5I\nHKGXWcK5E5gCbDGzxXhFsdOcc6HnGc5RhP/sVuKdsz/+9sBWV/yyT7HPzueAc+770IVm1g54GOjP\noZ8hhP9cc51zP4csy8a7HBUqO2Q8kYSgmQqRGHHOObzr9W2ATgBmdiZePUUO3szGBXjfyP8f4b/x\nHgyzjKBtg3/Zl7RNmaGGWfYMcDfwBl4dwLm+OHdS/n8nynv8CnHO/RPvW/rNwA94l16WhytoDaOy\nYswLXeCbVfoE72f+J7yajHPwLiGFqx8p6Wdf1t8JkYShmQqR2PL/P9XQ999BeHUS5/lnLgDMbGSU\n4//kG++4MOuOD3m/Ce8X19HAuqDl4fa9DJjinLszKMZkINwdHYaXNH0RtG0DoDVecWOlc85l4V1u\neN7MWgBf480G+S8BldQLYyNenUqozkHrwfvsfmNmKSGzFZ0iCLObb/trnHOv+xea2TkRjCFSrWim\nQiRGzKwucB7etfiVvsUHOXR3gH+7DnjfWiPmnCvE+8V5qZkdGTRmZ6BfyOYz8RKAm0KW30LxX7oH\nKf7vwVi8IsZwrvedr99Nvm0rtT+HmSWZWePgZc65HcCPFL20tI/ilxfAi6+1mQXuvDCzOnifyR7g\nS9/imXh36owO2s7w7nIpb3dP/wxD6Of6+wjGEKlWNFMhEh0DLvT9MgfvltKheLcq/sk5t9e3/H3g\nNmCmmf0/vM6bN+Fd1+8e5bEfxCsk/I+ZPYd3S+nNwHKCvoU755aY2VvA733f5ufjFSL6v20H/2J7\nH7jG12NhBXAqcDawo4QY6gOfmtk/gF/hXdqZ7Zyr7JmKRsD3ZjYdWIp3q+i5eLd+3ha03WLgSjN7\nHFgI7PXF9iJwA94tpCdx6JbSU4FbnXP7fPv/C1gAPG5mnYBVwAAOzdyUJylYhTdD9LgvAdyNNyNU\nKf08RBKBkgqR6DjgoaD3uXi/RG50zv0tsJFzn5vZdcBdwJN4RZN34l2SCE0qSmphXWS5c+6/ZtYP\neMIXw/d4/SraUnxq/xpgK16Xz0uBj/H6I6z2xew3Fu/WxSFACvAfvOv/M8PE5PCSmKG+49cDXse7\nXbOiwn0Gwcty8O7A6Id3B0kSXvHk75xzLwbt8xxwAl7h6e/xLme875zLNbOzgMeAYUBjvALXa51z\ngf4izrlCM7sQr833MLyC17d95zuHop+dP8aiC5w74CvSnYz388/1jfEsXkIU7tzDKfPvhEiiMK+2\nTERqC1/nySV4/ScyI9x3OF6fi5OD73ypLXy3C78FnOGcmxfveEQSTULUVJjXNvhVO9TGeKmZ9QzZ\nZqKZ/ehb/7GZHRuveEWqC1+xZajf413v/zLMOvEJ/ex8d3PcgncZo9YlVCLlEffLH75mQHOAT/GK\n3HbgXfP9JWibP+BNtw7Hmz5+BO8adWdXDR82JFKF7jSzdLxbXQ/gNac6D3ghuHlWhGrLrYxPm1ka\nXrOqZLx6iFOAu4ObWonIIXFPKvCuNW52zo0KWhbaz/5W4GHn3HsAvof5ZOFdI/5HlUQpUj3Nwytk\nvA/vNtfNeIWej1ZgzNpyzfQzvOLPi/DqTNbite0O7VAqIj5xr6kws+XAh0A7vMr0H4DnnHN/9633\n32N/onNuWdB+nwNfO+fGVXnQIiIiUkwi1FR0xLsd7Tu8iu7ngclmdrVvfWu8b0ZZIftl+daJiIhI\nAkiEyx9JwALn3P2+90vN7Nd4icZrpexnlDAN63toz3l496CX51kCIiIi4kkBOgAzwzyPplSJkFRs\n5VD3Qb+VeO2NAbbhJRCHU3S2ohVea95wzsO7b15ERESiMxTvOUXllghJxRyKP7PgeHzFms65DWa2\nDa+73zIAX5ve3nhNZMLZCPDaa6/RuXPnEjapXsaNG8eTTz4Z7zBioiadC+h8EllNOhfQ+SSymnQu\nK1eu5Oqrr4ZDz8Ipt0RIKp4E5pjZ3Xh3cvQGRhHUcx94CrjPzNbineTDeF0E3y1hzFyAzp0707Nn\nzxI2qV6aNGmic0lQOp/EVZPOBXQ+iawmnUuQiMsH4p5UOOcWmdlAvLa59+P1objVOfdG0DaTfPeL\nv4DXN382cIF6VIiIiCSOuCcVAM65GZTxdEPn3ARgQlXEIyIiIpFLhFtKRUREpAZQUlFNZGRkxDuE\nmKlJ5wI6n0RWk84FdD6JrCadS0XEvaNmZfA9jGzx4sWLa2LhjIiISKVZsmQJ6enpAOmRPo1YMxUi\nIiISEzU6qXjppUxeeuk1CgoK4h2KiIhIjVejk4o1aw5nzpy1ZGdnxzsUERGRGq9GJxUtW9aMbpoi\nIiLVQY1OKkRERKTqKKkQERGRmFBSISIiIjGhpEJERERiQkmFiIiIxISSChEREYkJJRUiIiISE0oq\nREREJCaUVIiIiEhMKKkQERGRmFBSISIiIjGhpEJERERiQkmFiIiIxISSChEREYkJJRUiIiISE0oq\nREREJCaUVIiIiEhMKKkQERGRmFBSISIiIjGhpEJERERiQkmFiIiIxISSChEREYkJJRUiIiISE0oq\nREREJCaUVIiIiEhMKKkQERGRmFBSISIiIjGhpEJERERiQkmFiIiIxISSChEREYkJJRUiIiISE0oq\nREREJCaUVIiIiEhMKKkQERGRmIh7UmFmD5pZYchrRdD6ZDN71sx2mNkeM5tuZq3iGbOIiIgUF/ek\nwudb4HCgte91RtC6p4CLgMuAPkBb4K2qDlBERERKVzfeAfgccM5tD11oZo2B64DBzrkvfMtGACvN\nrJdzbkEVxykiIiIlSJSZik5m9oOZrTOz18ysnW95Ol7i86l/Q+fcd8Bm4NQ4xCkiIiIlSISkYj5w\nLXAecCNwNPClmTXAuxSS75zbHbJPlm+diIiIJIi4X/5wzs0MevutmS0ANgFXArkl7GaAK2vsL76Y\nSFLSLq6+ej7169cHICMjg4yMjApGLSIiUv1lZmaSmZlZZFl2dnbU45lzZf5urnK+xOJj4BPfq2nw\nbIWZbQSedM79tYT9ewKLhwx5n+TkhUyadDMtWrSogshFRESqtyVLlpCeng6Q7pxbEsm+iXD5owgz\nawgcA/wILAYOAGcHrT8OaA/Mi0uAIiIiElbcL3+Y2Z+B9/AueRwBPISXSLzhnNttZi8BT5jZL8Ae\nYDIwR3d+iIiIJJa4JxXAkcD/A5oD24H/AKc45372rR8HHASmA8nAh8CYOMQpIiIipYh7UuGcK7Vq\n0jmXB9zie4mIiEiCSriaChEREamelFSIiIhITCipEBERkZhQUiEiIiIxoaRCREREYkJJhYiIiMSE\nkgoRERGJCSUVIiIiEhNKKkRERCQmlFSISFgvvvgi7du3p27dukyePLlc+2zatImkpCSWLVtWydEl\n1rFFxKOkQkSK2bNnD7fccgt33303P/74I9dff3259zWziI41YsQIBg0aFGmIxbRv355t27bRtWvX\nqPafPXs2AwYM4IgjjiApKYl///vf5drv9ddf58QTT6RBgwa0bduWkSNHsnPnzsD6qVOnkpSURJ06\ndUhKSiIpKYm0tLSoYgQoKCigZcuWTJo0Kez6hx9+mNatW3Pw4MGojyESLSUVIlLMpk2bOHDgABde\neCGtWrUiJSWl3Ps65yoxspKZGa1atSIpKbp/1vbt28eJJ57Is88+W+7EaM6cOQwfPpzRo0ezYsUK\npk+fzoIFC4olYU2aNGHbtm2B16ZNm6KKEaBevXpcffXVvPLKK2HXT506lWuvvZY6depEfQyRaCmp\nEImBvn37MnbsWMaNG0ezZs1o3bo1L730Ejk5OVx33XU0btyYTp068eGHHxbZ79tvv+XCCy+kUaNG\ntG7dmmHDhvHzzz8H1s+cOZMzzzyTpk2b0qJFC/r378/69esD6/1T/u+88w6//e1vadCgASeeeCLz\n588vNd4tW7ZwySWX0KhRI5o0acJVV13FTz/9BHi/lLp37w7A0UcfTZ06ddi8eXPYcRYsWEDPnj1J\nTU2lV69efP3110V+IRcWFjJq1Cg6duxIWloav/rVr4pcSnnooYeYOnUq7777buDb/JdffgnAXXfd\nxfHHH0+DBg045phjeOCBB0r99h16+WPXrl0MHTqUVq1akZaWxvHHH8/UqVNL3P/8889n4sSJXHrp\npeVOjObPn8/RRx/NmDFjOOqoozjttNO44YYbWLBgQZHtzIyWLVvSqlUrWrVqRcuWLcsc+9133yU9\nPZ3U1FSOPfZYJk6cSGFhIQAjR45k9erVzJ07t8g+n3/+ORs2bGDEiBHlil8k1pRUiMTItGnTaNmy\nJQsXLmTs2LHceOONXHHFFZx++ul8/fXX9OvXj2HDhpGbmwtAdnY2Z599Nunp6SxZsoSZM2fy008/\nceWVVwbG3LdvH7fffjuLFy9m1qxZ1KlTh4EDBxY79n333cedd97J0qVLOe644xgyZEjgF1A4l1xy\nCbt27WL27Nl88sknrFu3jsGDBwMwePBgPvnkEwAWLVrE1q1badeuXbExcnJy6N+/P127dmXJkiVM\nmDCB8ePHF9mmsLCQdu3aMX36dFauXMmDDz7Ivffey/Tp0wEYP348V155Jeeffz5ZWVls3bqV0047\nDYDGjRszbdo0Vq5cyeTJk/n73//Ok08+WerPIDihue+++1i1ahUzZ85k1apV/O///i8tWrQodf9I\nnXrqqWzZsoX/+7//AyArK4vp06dz0UUXFdlu7969dOjQgfbt23PppZeyYsWKUsf9z3/+w/Dhwxk3\nbhyrVq3ihRdeYOrUqfzxj38EoGvXrpx00km8/PLLRfZ75ZVXOO200zj++ONjeJYiEXDO1bgX0BNw\nQ4a870aMeNBt377diVSm3/zmN65Pnz6B9wcPHnQNGzZ0w4cPDyzbtm2bMzP31VdfOeece+SRR9z5\n559fZJwtW7Y4M3Nr1qwJe5yffvrJmZlbvny5c865jRs3OjNzr7zySmCbFStWuKSkJPfdd9+FHeOj\njz5y9erVcz/88EORfczMLVq0yDnn3DfffOOSkpLcpk2bSjznF154wbVs2dLl5eUFlj3//PMuKSnJ\nLV26tMT9br75ZnfFFVcE3l977bVu4MCBJW7v95e//MWdfPLJJa73fxb+Yw8YMMCNHDmyzHHDMTP3\n7rvvlmvbf/7zn65Ro0auXr16zszcJZdc4g4cOBBYP2/ePPfqq6+6pUuXui+//NL179/fNWnSxH3/\n/fcljnnOOee4xx57rMiy1157zbVt2zbw/vnnn3eNGzd2+/btc845t2fPHtewYUM3ZcqUSE5VpJjF\nixc7wAE9XYS/fzVTIRIj/ksGAElJSTRv3pxu3boFlh1++OEAgcsMS5cuZdasWTRq1Cjw6ty5M2bG\nunXrAFi7di1DhgzhmGOOoUmTJnTs2BEzK3Y5Ivg4bdq0wTkXOE6oVatW0a5dO9q2bRtY1rlzZw47\n7DBWrlxZ7vNdtWoV3bt3p379+oFlp556arHtnn32WU466SRatWpFo0aNePHFF0u8nBLszTff5Iwz\nzqBNmzY0atSI++67r1z7+f3ud78jMzOTHj168Ic//IF58+aVe9/yWrFiBbfeeisTJkwIzDZt2LCB\nG264IbDNKaecwtVXX0337t0588wzefvtt2nZsiUvvvhiieMuXbqUiRMnFvm7MXr0aLKysgIzXRkZ\nGRw4cIB//OMfALzxxhskJSVxxRVXxPw8RcpLSYVIjNSrV6/IezMrtgwIXJbYu3cvAwYMYNmyZSxd\nujTwWrNmDX369AHg4osv5pdffuHvf/87CxYsYMGCBTjnyM/PL/HY/ksAJV3+cM6FLUQsaXlJyrP9\nG2+8wR133MHo0aP5+OOPWbp0KSNGjCgWf6j58+dz9dVXc/HFF/PBBx/wzTffcO+995a5X7Dzzz+f\nzZs3M27cOLZu3crZZ5/NnXfeWe79y+Oxxx7jjDPO4LbbbqNr166ce+65PPfcc7z88stkZWWF3adu\n3br06NGDtWvXljju3r17eeihh4r8vfj2229ZvXp1oGi2cePGXH755YGCzSlTpnDllVdW6M4SkYqq\nG+8ARGqrnj178vbbb3PUUUeFvWNh586drF69mpdeeonTTz8d8K61h4r0Fs4uXbqwefNmfvjhB444\n4gjA+8adnZ1N586dIxrn9ddfJz8/PzBbETobMHfuXE4//fQi39z9szB+9evXL1aAOXfuXDp06MBd\nd90VWLZx48YyYwr9LJo3b86wYcMYNmwYZ5xxBnfeeWeJt2JGIycnp1jimJSUhJmVWOxZWFgYKNAt\nSc+ePfnuu+/o2LFjqccfOXIkffv25YMPPmDu3Lk8/vjjkZ+ESAxppkIkTsaMGcPOnTsZPHgwixYt\nYv369cycOZPrrrsO5xxNmzalefPmvPjii6xbt45Zs2Zx++23F/vFWdIvr5Kcc845dOvWjaFDh/L1\n11+zYMEChg8fTt++fenZs2e5xx0yZAhmxqhRo1i5ciUzZswo9kutU6dOLFq0iI8++og1a9bwwAMP\nsHDhwiLbdOjQgWXLlrF69Wp+/vlnDhw4QKdOndi8eTNvvvkm69evZ/LkyfzrX/8q89yCY37wwQf5\n97//zbp161i+fDnvv/8+Xbp0KXHfffv2sXTpUr755hsA1q9fz9KlS9myZUtgm3vuuYfhw4cH3vfv\n35+3336b559/ng0bNjBnzhxuvfVWevfuTevWrQGvb8THH3/Mhg0b+Prrrxk6dCibNm1i1KhRJcby\nwAMPMG3aNCZOnMiKFStYtWoVb775Jvfff3+R7fr06cMxxxzDsGHD6Ny5M7179y7zMxKpTEoqRGIg\n3GxBWcvatGnDnDlzKCws5LzzzqN79+7cdtttNG3aFDPDzHjzzTdZvHgx3bp14/bbb+cvf/lL1McO\n9u6779K0aVPOOuss+vXrx7HHHssbb7wR0RgNGjTgvffe49tvv6Vnz57cf//9xWYBbrjhBgYNGsTg\nwYM55ZRT2LlzJ2PGjCmyzejRozn++OMDdRdz586lf//+jBs3jltuuYUePXowf/58HnjggVLjCY25\nfv363HPPPZxwwgn85je/oW7dumRmZpa476JFi+jRowfp6emYGbfffjs9e/bkwQcfDGyzdevWIknG\n8OHDeeKJJ3j22Wfp1q0bV111FZ07d+att94KbPPLL79w/fXX06VLFy666CL27t3LvHnz+NWvflVi\nLP369eP999/n448/plevXpx66qk89dRTdOjQodi21113Hbt27WLkyJFlfj4ilc0i/ZZTHZhZT2Dx\nkCHvk5y8kEmTbo75rWQiIiI10ZIlS0hPTwdId84tiWRfzVSIiIhITCipEBERkZhQUiEiIiIxoaRC\nREREYkJJhYiIiMSEkgoRERGJCSUVIiIiEhNKKkRERCQmlFSIiIhITCipEBERkZhQUiEiIiIxoaRC\nREREYkJJhYiIiMSEkgoRERGJCSUVItVM3759ue222wLvjz76aCZPnhzHiA65/vrrad68OXXq1GHZ\nsmXl2mfq1Kk0bdq0kiMr+djNmjWLy7FFaiIlFSLV3KJFi7j++uvjHQYffvgh06ZNY8aMGWzdupWu\nXbuWe18zi+hYsUqkBg8ezOrVq6Pe/29/+xt9+/alSZMmJCUlsXv37jL3eeihh0hKSiry6tKlS5Ft\n1q9fz6BBg2jVqhVNmjRh8ODB/PTTT1HHuWTJEpKSkliwYEHY9WeffTaXX3551OOL+CmpEKnmmjdv\nTkpKSrzDYO3atbRp04bevXvTqlUrkpIS/5+X5ORkWrRoEfX++/fv54ILLuDee++NKDHq2rUrWVlZ\nbNu2jW3btvGf//wnsC4nJ4d+/fqRlJTE559/zty5c8nLy6N///5Rx9mzZ09OOOEEXn755WLrNm/e\nzOeff86oUaOiHl/EL/H/rxepBvr27cvYsWMZN24czZo1o3Xr1rz00kvk5ORw3XXX0bhxYzp16sSH\nH35YZL9vv/2WCy+8kEaNGtG6dWuGDRvGzz//HFifk5PDsGHDaNSoEUcccQRPPPFEsWOHfmt/8skn\n6d69Ow0bNqR9+/aMGTOGffv2Bdb7Lzd89NFHdOnShUaNGnHBBReQlZVV6jl+8cUX9O7dm5SUFNq2\nbcvdd99NYWEhACNGjGDs2LFs3ryZpKQkOnbsWOI4U6ZM4aijjqJhw4ZcdtllRc4XvG/pl156Ka1b\nt6ZRo0b06tWLTz/9tMhnvWnTJsaNG0dSUhJ16tQBYOfOnQwZMoR27drRoEEDunfvzhtvvFHqOYVe\nelm2bBm//e1vady4MU2aNOHkk09myZIlJe4/duxY7rzzTnr37l3qcULVrVuXli1b0qpVK1q1alXk\nEsycOXPYtGkTU6dOpUuXLvz6179m6tSpLFq0iFmzZpU4pnOOP/3pT3Ts2JG0tDR69OjBW2+9FVg/\ncuRI3nzzTXJzc4vs9/LLL9O2bVvOO++8iM5BJBwlFSIxMm3aNFq2bMnChQsZO3YsN954I1dccQWn\nn346X3/9Nf369WPYsGGBf9Szs7M5++yzSU9PZ8mSJcycOZOffvqJK6+8MjDm+PHjmT17Nu+99x4f\nffQRn3/+OYsXLy41jjp16vD000+zfPlypk2bxmeffcYf/vCHItvk5OTw+OOP8/rrrzN79mw2b97M\n+PHjSxzzxx9/5KKLLqJ3794sW7aM559/npdeeolHHnkEgMmTJzNx4kSOPPJIsrKyWLhwYdhxvvrq\nK0aNGsXYsWP55ptv6Nu3b2AMv71793LRRRcxa9YsvvnmGy644AIGDBjA999/D8Dbb7/NkUceycMP\nP8y2bdvYunUrALm5uZx00knMmDGD5cuXc8MNNzBs2LASY/ELnmEYOnQo7dq1Y/HixSxZsoS77rqL\nevXqlbp/NNasWcMRRxzBMcccw9VXX82WLVsC6/Ly8jAz6tevH1iWnJxMUlJSkRmNUI8++iivvfYa\nL774IitWrGDcuHFcc801zJ49O3Buubm5TJ8+vch+06ZNY8SIERFfghIJyzmXUC/gbqAQeCJoWTLw\nLLAD2ANMB1qVMkZPwA0Z8r4bMeJBt337didSmX7zm9+4Pn36BN4fPHjQNWzY0A0fPjywbNu2bc7M\n3FdffeWcc+6RRx5x559/fpFxtmzZ4szMrVmzxu3du9clJye7t956K7B+586dLi0tzY0bNy6wrEOH\nDu6vf/0DdqLbAAAgAElEQVRribFNnz7dtWzZMvB+ypQpLikpyW3YsCGw7LnnnnNt2rQpcYx77rnH\nde7cuciy5557zjVu3Djw/qmnnnJHH310iWM459yQIUPcxRdfXGTZ4MGDXdOmTUvdr2vXru7ZZ58N\nvC/rnP0uvvhid8cdd5S4fsqUKUWO3bhxYzdt2rQyxw31+eefu6SkJJednV3mth9++KGbPn26++9/\n/+s++ugjd9ppp7mjjjrK7d271znn3Pbt291hhx3mfv/737ucnBy3d+9ed/PNN7ukpCR34403hh0z\nLy/PNWjQwM2fP7/I8lGjRrmhQ4cG3g8ePNj17ds38P7TTz91derUcevWrYv4nKXmWrx4sQMc0NNF\n+Ds8oWYqzOxkYDSwNGTVU8BFwGVAH6At8BYiCaR79+6BPyclJdG8eXO6desWWHb44YcDBAruli5d\nyqxZs2jUqFHg1blzZ8yMdevWsW7dOgoKCujVq1dgjKZNm3L88ceXGscnn3zCOeecw5FHHknjxo25\n5ppr+Pnnn9m/f39gm7S0NDp06BB436ZNm1ILAVetWsWpp55aZNnpp5/O3r17AzMI5bFy5cpilwpC\nx923bx/jx4+nS5cuNG3alEaNGrFq1So2b95c6tiFhYU8/PDDdO/enebNm9OoUSM++uijMvcLdttt\ntzFy5EjOPfdc/ud//of169eXe9/yOu+887jsssvo2rUr5557LjNmzGDXrl384x//AKBFixb885//\n5P3336dhw4Y0bdqU3bt306NHj8ClnlBr164lJyeHc889t8jfp1dffZV169YFths5ciRffvklGzZs\nALxLH3369Cn1cpVIJOrGOwA/M2sIvAaMAu4PWt4YuA4Y7Jz7wrdsBLDSzHo558KXM4tUsdBpcjML\nO3Xur0PYu3cvAwYMYNKkSf4ZtoA2bdoE7kqIZFp606ZN9O/fnzFjxvDoo4/SrFkzZs+ezahRoygo\nKCA1NbXEWENjCOacKxaHf/tI4gs3Tqjbb7+dTz/9lMcff5xjjjmG1NRULrvsMvLz80vdb9KkSTz9\n9NP89a9/pWvXrjRo0IBbb721zP2CPfjggwwdOpQPPviAGTNmMGHCBN544w0uueSSco8RqSZNmnDc\nccexdu3awLJzzjmHNWvWsHPnTurWrUvjxo1p06YNRx99dNgx9u7dC8CMGTNo27ZtkXXJyclFxm3X\nrh1Tpkxh/PjxvPPOO/ztb3+rhLOS2iqRZiqeBd5zzoVWIp2El/wEKrWcc98Bm4FTEammevbsyfLl\nyznqqKPo2LFjkVdqairHHnssdevWZf78+YF9fvnll1JvgVy8eDGFhYX85S9/oVevXhx77LH88MMP\nFY61S5cuzJ07t8iyOXPmBApIIxkn+HwA5s2bV+T93LlzufbaaxkwYAC//vWvadWqFRs3biyyTf36\n9Tl48GCx/S655BIyMjLo1q0bRx99NGvWrCl3bH7HHnsst956KzNnzmTgwIG88sorEY8Rib1797Ju\n3TratGlTbF2zZs1o3Lgxs2bNYvv27QwYMCDsGF26dCE5OZlNmzYV+7sU+vMZMWIEU6ZM4fXXXyc5\nOZnLLrusUs5LaqeESCrMbDBwIl49RajDgXznXOgN4FlA68qOTaSyjBkzhp07dzJ48GAWLVrE+vXr\nmTlzJtdddx3OORo0aMDIkSO54447+Oyzz/j2228ZMWJEiVPg4P1CPHDgAJMnT2bDhg28+uqrvPDC\nCxWO9aabbmLLli3ccsstfPfdd7z77rtMmDCB22+/PaJxxo4dy4cffsjjjz/O2rVreeaZZ5g5c2aR\nbTp16sTbb7/N0qVLWbp0KUOHDi02i9KhQwe+/PJLfvzxx8DdI506deLjjz9m3rx5rFy5khtuuIFt\n27aVO7bc3FxuueUWvvjiCzZv3sycOXNYuHBhsR4SwbKysli6dClr1qzBOceyZctYunQpv/zyS2Cb\ns88+m+eeey7w/o477uDLL79k06ZNzJ07l4EDB1K3bl0yMjIC20yZMoWvvvqK9evX89prr3HllVdy\n22230alTp7BxNGzYkPHjxzNu3DimTZvG+vXr+frrr3nmmWd49dVXi2w7YsQIfvjhB+69914yMjKK\nzGSIVFTckwozOxKvZuJq51xBJLviFZJIBLKzs9m6dStbt24lOzs73uHUGOGm9Mta1qZNG+bMmUNh\nYSHnnXce3bt357bbbqNp06aB7f785z9z5plnMmDAAPr168eZZ55Jenp6iWN2796dJ554gkmTJtGt\nWzcyMzN57LHHKnx+bdu2ZcaMGSxcuJATTzyRm266idGjR3PvvfdGNE7v3r3529/+xuTJkznxxBP5\n5JNPuP/++4ts88QTT9C0aVNOP/10LrnkEs4//3x69uxZZJuJEyeyceNGjjnmGFq1agXAfffdR8+e\nPTn//PP57W9/S5s2bRg4cGC5Y6tTpw4///wzw4cP5/jjj2fw4MFcdNFFTJgwocR9nn/+eXr06MEN\nN9yAmXHWWWfRs2dP3nvvvcA2GzZsYMeOHYH333//PUOGDOFXv/oVgwcPpmXLlsyfP5/mzZsHtvnu\nu++49NJL6dKlC4888gj3338/kyZNKjX+hx9+mAceeIDHHnuMLl26cMEFFzBjxoxil0zatWvHOeec\nQ3Z2Ntddd125Px+R8rDSrqNWSQBmlwBvAwfxEgWAOngJw0HgfOAT4LDg2Qoz2wg86Zz7a5gxewKL\njziiF0lJu+jS5ejA7VkZGRlFvhHUJtnZ2Tz88DPs2OHlbi1a1OP++2+mSZMmcY5MRETiITMzk8zM\nzCLLsrOz+fLLLwHSnXMlN2oJIxEKNT8BuoUsmwKsBB4DfgAKgLOBdwDM7DigPTCPUpx11gMkJy9k\n0qSbK9Q1r6bIyclhx44CUlMHAbBjx9vk5OQoqRARqaXCfdFesmRJsRnR8op7UuGc2wesCF5mZvuA\nn51zK33vXwKeMLNf8PpUTAbm6M6P6KSltQQg6A5DERGRCot7UlGC0Gsy4/AuhUzHa4T1ITCmqoMS\nERGRkiVkUuGc+23I+zzgFt9LREREElDc7/4QERGRmkFJhYiIiMSEkgoRERGJCSUVIiIiEhNKKkRE\nRCQmlFSIiIhITCipEBERkZhQUiEiIiIxoaRCREREYkJJhYiIiMSEkgoRERGJCSUVIiIiEhNKKkRE\nRCQmokoqzOxqM0uJdTAiIiJSfUU7U/EUsM3MXjCzXrEMSERERKqnaJOKtsBo4EhgjpktN7Pbzaxl\n7EITERGR6iSqpMI5l++c+6dz7iKgPTANGAl8b2Zvm9lFZmaxDFREREQSW4ULNZ1zW4FPgM8AB5wE\nZAJrzOzMio4vIiIi1UPUSYWZtTCz35vZUmAO0Aq4FDgKOAL4F94MhoiIiNQCdaPZyczeAS4ENgB/\nB6Y657YHbbLHzCYBt1U8RBEREakOokoqgN3AOc652aVssx3oFOX4IiIiUs1ElVQ454aXYxsHrItm\nfBEREal+om1+9aSZ3Rxm+Rgze7ziYYmIiEh1E22h5hXA/DDL5wFXRR+OiIiIVFfRJhUtgF/CLN/t\nWyciIiK1TLRJxTrgvDDLz8O7I0RERERqmWjv/ngS+KuZNQdm+ZadDdwJjI9FYCIiIlK9RHv3x9/N\nLBW4B3jIt/h7YKxz7uVYBSciIiLVR7QzFTjnngaeNrM2wH7n3K7YhSUiIiLVTdRJhZ/v2R8iIiJS\ny0Xbp6Klmb1iZpvNLNfM8oNfsQ5SKkd+fi5ZWVlkZ2fHOxQREakBop2pmAIcA/wZ2Ir3dFKpRvLy\ndrNs2X959NFC2rdvwv3330yTJk3iHZaIiFRj0SYVfYA+zrmvYxmMVJ2Cgv3k5tbDuT7s2LGInJwc\nJRUiIlIh0fap+B7NTtQIyclKJEREJDaiTSrGAX8ysyNjGYyIiIhUX9Fe/ngVaARsMrPdQEHwSudc\nq4oGJiIiItVLtEnFXTGNQkRERKq9aDtqvhTrQERERKR6i7amAjPrYGYTzOxVM2vlW9bPzDrHLjwR\nERGpLqJtfnUmsBw4C7gSaOhblQ5MjE1oIiIiUp1EO1PxP8AE51xfILiD5qfAKRWOShJOdnY2W7du\nZevWrerAKSIiYUVbqNkdGBpm+U9Ay0gGMrMbgd8BHXyLlgMTnXMf+tYnA08AVwHJwEzgJufcT1FF\nLhHLzs7m4YefYccO7yafFi3qqQOniIgUE+1MRTbQOszyE4AfIhxrC/AHvEsn6cAs4N2g2oyngIuA\ny/A6ebYF3ooiZolSTk4OO3YUkJo6iNTUQezYUUBOTk68wxIRkQQT7UzFm8BjZnY5vs6aZtYb+Avw\nWiQDOec+CFl0n5n9DjjFzH4ArgMGO+e+8B1nBLDSzHo55xZEGb9EIS3Nm4Tavz/OgYiISEKKdqbi\nbmA98CNekeYKYC6wCHg42mDMLMnMBgNpwDy8mYu6eLUaADjnvgM2A6dGexwRERGJvWj7VOQBI8xs\nItANL7FY4pxbFc14ZtYVL4lIAfYAA51zq8ysB5DvnNsdsksW4S+/iIiISJxEe/kDAOfcBmBDDOJY\nhVePcRhe7cQ0M+tTyvaGHmgmIiKSUKJKKszsxdLWO+euj2Q859wBvMspAEvMrBdwK/APoL6ZNQ6Z\nrWiFN1tRqi++mEhS0i6uvno+9evXByAjI4OMjIxIwhMREamRMjMzyczMLLKsIm0Dop2paBPyvh7w\na7yHjH0ZdTSHJOHdProYOACcDbwDYGbHAe3xLpeU6qyzHiA5eSGTJt1MixYtYhCWiIhIzRHui/aS\nJUtIT0+Parxoayr6hy4zs7rA83hFm+VmZn8E/g/v1tJGeP0vzgL6Oed2m9lLwBNm9gtevcVkYI7u\n/BAREUksFaqpCOacO2BmfwY+x2tWVV6HA9PwZj+ygWV4CcUs3/pxwEFgOt7sxYfAmBiFLSIiIjES\ns6TC52i8SyHl5pwbVcb6POAW30tqqOzsbHJyckhLS1OnThGRairaQs1JoYvwZhoGAK9XNCipXYLb\ngKsFuIhI9RXtTEVo46lCYDtwF/C3CkUktY6/Dbhzfdix40tycnKUVIiIVEPRFmqeGetARFJSDiMv\nL95RiIhItKJt0y0iIiJSRLQ1FQspZ0dL51yvaI4hIiIi1Uu0NRWfATcAqznUhOoU4HjgBUCT2CIi\nIrVMtEnFYcCzzrl7ghf6GlkdXtZtoiIiIlLzRFtTcSXwSpjlU4Aroo5GREREqq1ok4o8vMsdoU5B\nlz5ERERqpWgvf0wGXjCzHsACvKLNU4DRwJ9iFJuIiIhUI9H2qfijmW3Aezy5v35iJXC9c+7/xSo4\nERERqT6ifvaHL3lQAiEiIiJABZpfmVljM7vWzCaaWVPfshPMrE3swhMREZHqItrmV12BT4AcoB3e\nXR+/AFcBRwDDYxSfiIiIVBPRzlQ8iXfp4xggN2j5B0CfigYVS/n5uWzbto2tW7eSnZ0d1RjZ2dkV\n2l9ERKQ2iLam4mTgd845Z2bBy3/AewR6QsjP38fKlf/lkUdeIyUlJarHauux3CIiIuUT7UxFAdAw\nzPJjgR3RhxNbBw/mkZtbj5SUgaSmDmLHjgJycnIiGqPoY7kj319ERKS2iDapeA+438z8Mx3OzI4A\nHgPejklkMZSW1oK0tJYVGiMl5bAYRSMiIlIzRZtU3A40A7YBqcAsYD1efcU9pewnIiIiNVS0za9+\nAfqa2VnACXiXQpYAM51z5Xokek2RnZ1NTk4OaWlpxWotSluX6IJjFxERKY+Ikwozqwe8D9zsnPsC\n+CLmUVUTpRVxVucCz9DYR4++PN4hiYhINRDx5Q/nXAGQjve8j1qttCLO6lzgGRr7/v374x2SiIhU\nA9HWVLwOjIhlINVZaUWc1bnAszrHLiIiVS/aPhUOuNnMzgEWAfuKrHTuzooGJiIiItVLtElFOrDM\n9+fuIetq/WURERGR2iiipMLMOgIbnHNnVlI8UgL/3RgFBQXUq1cv8F8gcHdJtHeb5OfnkpWVlRB3\nqSRSLCIiEplIZyrW4LXh/gnAzN4ExjrnsmIdmBzivxvjxx/3sHr1cjp06MTGjWs47rhu1K9fnxYt\n6jF27DVMnvxqxHeb5OfvZcWK//Loo4W0b9+E+++/uQrOqKRY9rBsWdFYlFiIiFQfkRZqWsj7C4EG\nMYpFSuC/G6OgIJ1du+qQm3siu3bVoW7d/oH24zt37ozqbpODB3PJza2XEHepHDiQOLGIiEjkor37\nQ+IgJaUxAMnJjQBITS3efjzaOzaSkxNnRiCRYhERkfKLNKlwFC/EVGGmiIiIRFxTYcAUM8vzvU8B\nnjez0FtKB8UiuHjyFz1mZWWRn59PcnLp2/sLDIFa19ra/1kB5SqwrM7ty0VEpGSRJhVTQ96/FqtA\nEklwm+qcnD0sX76ek0/OK3H74ALDtLS0WtXaOvizAsosEg3XvlxERGqGiJIK51yt6KLpL4xMTR1E\nYeF28vKe5sCBA9Qt4dPyFximpAwkNbUBO3a8XWtaWwd/VgA7drxNTk5OiUlF0RbgX6oYU0SkBom2\n+VWtkJbWksLCwnJv7xVONqSW5BNF+AtGy3vuKSmHkVfy5I+IiFRDuvtDREREYkIzFZUgPz+X7du3\nl6vAszoK7nopIiLip6QixvLydrNs2X+ZPHk369dvLbXAszryn5+/62VtKUgVEZGy6fJHjBUU7Pd1\nhTyFvDzHgQMH4h1STB06P6/rZW0pSBURkbIpqagk/q6XNZW6XoqISCglFSIiIhITqqmogUK7e1ZW\n18rgglQREZG4JxVmdjcwEPgVsB+YC/zBObc6aJtk4AngKiAZmAnc5Jz7qeojTmzhuntWxiPE/Y9M\n9xekNmuWS3JySkyPISIi1UsiXP44E3ga6A2cA9QDPjKz1KBtngIuAi4D+gBtgbeqOM5qoWh3z0GV\n9gjxQ49M9wpSCwpqVkGqiIhELu4zFc65C4Pfm9m1wE9AOvAfM2sMXAcMds594dtmBLDSzHo55xZU\nccjVQlV196zpBakiIlJ+iTBTEeowvMep7/S9T8dLfj71b+Cc+w7YDJxa5dGJiIhIWHGfqQhmZoZ3\nqeM/zrkVvsWtgXzn3O6QzbN862q94ILJOnXiHY1HjzcXEal9EiqpAJ4DugBnlGNbw5vRKNG8eU+y\ne/dWZsy4njp16pCfv4l33mnFTTfdFItYE0JoB89f/zr+kze7d+/m8cdfLvJ4cyUWIiKJJzMzk8zM\nzCLLsrOzox4vYZIKM3sGuBA40zn3Y9CqbUB9M2scMlvRCm+2okSnnjqOZcveol+/x0lNTePnn19g\n4MCBsQ8+jop28HybgwfjXzC5f//+Yo83V1IhIpJ4MjIyyMjIKLJsyZIlpKenRzVeQtRU+BKKS4C+\nzrnNIasXAweAs4O2Pw5oD8yrsiATXCIWTKakHBbvEEREpArFfabCzJ4DMoABwD4zO9y3Kts5l+uc\n221mLwFPmNkvwB5gMjBHd36IiIgkjrgnFcCNeLURn4csHwFM8/15HHAQmI7X/OpDYEykBwp+ZHe8\npuNVwBg5/2dWUFBAvXr19NmJiCSouCcVzrkyL8E45/KAW3yvqIQ+sjsexYPZ2dk8/PAzKmCMgP8z\n+/HHPaxevZzjjutG27YN9NmJiCSghKipqAqhj+yujC6TZcnJyQkqYIxPDNWN/zMrKEhn1646FBSc\nps9ORCRB1Zqkwi8RHtmtAsbIpaQ0BhLj5yciIuHVuqRCREREKoeSChEREYmJuBdq1lbluRPFf9dD\nVlZWhVtwZ2dnB8aJNE5/C3AREZHSKKmIg/z8PWXeiRJ8p0hOzh6WL18fdQtuf9vszZt3snz5epo1\ny40oTn8L8PLuJyIitZMuf8TBgQO5Zd6J4r/rITV1ECkpF5KX56JuwX2obfYp5OU5CgrKN86hOCPb\nT0REaifNVMRRee5kSEtrSWFhYUyO57+DIlKJ2AJcREQSj2YqREREJCZq5UxFIrTrltL5f0benytW\npCoiIlWj1iUV+fl7WbEivu26pXTBPyM4WKEiVRERqTq17vLHwYNlF0lKfPl/RikpAytcpCoiIlWn\n1s1U+Kndc+JLTW0B7It3GCIiUk61bqZCREREKketnamAosWABQUF1KtXj7S0tDK3r6wCT38HzdJi\niFRwR8x4FDsGf8axPC8REUk8tTapCC4GrFs3idWrl3Pccd1o27YBo0dfXur2/gLPWAruoNmiRb2w\nMUQqL293kY6YVV3sGNw5NC0tLWbnJSIiianWXv4ILgasW/dcdu2qQ0HBaezYUcD+/ftL3L6yCjz9\nHTT944eLIVIFBfuLdMSs6mJHf0fOlJSBpKYOitl5iYhIYqq1MxV+wcWA5SnerOwCz5SUw8jLi+2Y\n8e6ImZragrS0hiifEBGp2WrtTIWIiIjEVq2fqQhVnkd9V3a3Rz1uPHLBRa5qZiYiEh9KKoL4izFL\ne9R3ZXd71OPGIxda5KouqSIi8aHLH0EOFWOW/Kjvyu72qMeNRy60yFVdUkVE4kMzFWGUp7Cxsrs9\nxru4sjqqjCJXEREpP81UiIiISExopqIKlFbYmUiP+I5FLKV18Axel5wcm+NlZ2eTlZUVGDOa/csq\n8PRvA6gQVESkFEoqKllphZ2J9IjvWMRSWgfP0HUnnPBzoNtmtMfzF2hu3ryT5cvXc/LJkV37KE+B\nZ/A2gApBRURKocsflay0ws5EesR3LGIprYNn6Lq8vL0VPt6hAk1vzAMHot2/5AJP/zapqYMCXUFV\nCCoiEp5mKqpIaYWdifSI71jEUlqRaei6WBwvJaVxBfcvu8AzLa0lgLqCioiUQjMVIiIiEhOaqRAJ\nURmPoK9M6iYqIolCSYVIkMp4BH1lUjdREUkkuvwhEqQyHkFfmdRNVEQSiZIKkTBSUg6LdwgRqW7x\nikjNpKRCREREYkJJhYiIiMSECjWl2qmM1uahY0bT8ltEpLZTUiHVSmW0Ns/P31OsZXikLb9FRESX\nP6SaqYzW5gcOFB8z0pbfIiKimQqppiqjtXkitUsXEamONFMhIiIiMZEQMxVmdiZwB5AOtAEudc79\nO2SbicAo4DBgDvA759zaqo5VEltwwWVBQQH16tUL/Leq21j722cDaqEtIrVCQiQVQAPgG+Bl4K3Q\nlWb2B+BmYDiwAXgEmGlmnZ1z+VUZqCSu4CLOunWTWL16OR06dGLjxjUcd1w32rZtUGVtrIPbZwNq\noS0itUJCXP5wzn3onHvAOfcvwMJscivwsHPuPefct8AwoC1waVXGKYktuIizbt1z2bWrDrm5J7Jr\nVx0KCk6r0jbW/vbZqamDSE0dpBbaIlIrJERSURozOxpoDXzqX+ac2w18BVTsXkKpkVJTW5Ca2hyA\n5ORGvv/GZ4YgLa0laWkt43JsEZGqlvBJBV5C4YCskOVZvnUiIiKSABKlpiIahpdsiFQ7KuIUkZqo\nOiQV2/ASiMMpOlvRCvi6tB3nzXuS3bu3MmPG9Th3gB07VtOsWcdKDFWkbCriFJFEkZmZSWZmZpFl\n2dnZUY+X8EmFc26DmW0DzgaWAZhZY6A38Gxp+5566jiWLXuLfv0e5+DBPXz66QTatTuTnTvXV37g\nIiUILuIE2LHjbXJycpRUiEiVy8jIICMjo8iyJUuWkJ6eHtV4CZFUmFkD4FgO3fnR0cxOAHY657YA\nTwH3mdlaYCPwMPA98G4cwhWJCX8B5/79cQ5ERCRGEiKpAE4CPsOrkXDA477lU4HrnHOTzCwNeAGv\n+dVs4AL1qBAREUkcCZFUOOe+oIw7UZxzE4AJVRGP1HzZ2dlkZWWV+uj0/Pxctm/fTn5+/HNXf2Gn\nijpFJJElRFIhUpX8hZKbN+8s8dHp/u6ckyfvZv36rTRrlktyckocoi1a2KmiThFJZNWhT4VITPkL\nJZ07pcRHp/u7c/q3KSiI36PQD8XbR505RSShKamQWislpXGZ2/g7ciaClJTD4h2CiEiplFSIiIhI\nTKimQiTO/I9rj1cRZnB3z3g9Jl5EagYlFSJxlJe3m2XLvMe1t2/fpMqLMIOLQPPzc1m9enmVPyZe\nRGoOXf4QiaOCgv2+gtD4FGEGd/f0Py6+qh8TLyI1h2YqRBJAvB7N7peW1pLCwsKEiEVEqi/NVIiI\niEhMaKZCag1/QaT355I7aZZnjKoqaAzu/JmcXPQc0tLSyrW/OnGKSFVRUiG1gr9D5qOPFgIHS+yk\nWRp/UeVDD+1ny5b1lV7QGNr584QTfg4UdaalpdGiRT1Gj768zP3ViVNEqoouf0it4O+QmZIykJSU\nC0vspFkaf1FlQUF6lRQ0hnb+zMvbGziH1NRB7NhRwP5SHnGqTpwiUtU0UyG1SmpqC2Bfhcbwd9ms\nqoLG0M6fqaktSEtrWO5HpqekHEZeXiUEJiISQjMVIiIiEhNKKkRERCQmdPlDpAKC78YIviOkOgi+\ns6Sqj+uv70iE1uS6M0YkdpRUiEQp+I6SunWTirS4Lu2ujEQQemdJs2a5VXrcHTsKAOJyV0oixCBS\nU+nyh0iUgu8oCW1xXdpdGYkg9M6SgoLI7oSp6HFTUwcF7mCJZ2vyeMUgUlNppkKkgoLvKKluLa5D\n7yypKmlpLQHKfQdLTY1BpKbRTIWIiIjEhGYqRGIsPz+X7du3R10A6S8i9BdRltROPPg4ycllxxRc\nULpz586oW5Wr9beIlERJhUgM+Ys3J0/ezfr1W2nWLJfk5JRy7797924ef/xl33X+PSW2E/e3DPcf\n5+STS+5ulZ+/J9De219Q2q7d0axevSXiVuVq/S0ipdHlD5EY8hdvRlsAuX///kARYWntxP0tw/3H\nOXCg5OMcOBCuoPSkqFqVq/W3iJRGMxUilcDfyjtaaWktKSwsjOlxihaUViw+tf4WkXA0UyEiIiIx\noZkKkSrgL5QMLpIMt01FCjxjWYwZ6fFCizbDdawM18HTP0bwNv79/B1KgzuVlqd+ozIKScszprp0\niroP5UsAABEvSURBVCipEKl0/qLKhx7az5Yt6wNFksFdLMMVeEYiXHfPaIsxy3e8Q8WfaWlpRYo2\nw3WsHDv2GiZPfjWkg2d+YIz27ZsEttmxo4D8/FxWr15Ohw6d2LhxTaBTaVmFoZVRSFqeMdWlU8Sj\nyx8ilcxfVFlQkF6kSDK4iLOiBZ7hu3tGV4xZHsHFn6FdKcN1rNy5c2exDp6Hik37FNkmNXVQ4Bxy\nc08s0qm0rMLQyigkLc+Y6tIp4tFMhUgV8RdHllYkWdECylgWY5b3eGlpDcN2pQzXsTJcB8/QLqTB\nRaqHPrPIvvFXRiFpecZUl06p7TRTISIiIjGhmQoRKVFo4WRZxZ9V/Tj10gooQ4tAy4ov2gLPio6p\nAk+pSZRUiEhYwd09/YWTpRV/+rcPLsaMpJtopMIVUPoFF5K2b98ksC70ce/++ILPNZIiy3CPkI9k\nTBV4Sk2jyx8iElZwd8/yFH/6t6+qx6mXVkDpLyQNXlfa494PxR5ZgWdFx1SBp9Q0mqkQkVKFK5ws\nTVU/Tr20AspwBZ6lxRdtgWdFx1SBp9QUmqkQERGRmNBMhYgUE2l3z+DtK6uDZ7Dg4shIHvseLr7Q\nR8iHdgqNRmmPpQ8u3oyGHj0viUxJhYgUEWl3z9DHsFdGB89gocWRpT/2/VCnUThY7FHyobGfcMLP\nxTqFjh59eUTxlfZY+tDi0kjH1qPnJdHp8oeIFBFpd8/Qx7BXRgfPYKHFkaU99j2402i4R8mHxp6X\nt7dYp9D9ERY6lPZY+tDi0kjH1qPnJdEpqRCRsCLtyFkVHTyDRVIQmpragtTU5iWuD43d6xTaMurY\nwo0ZLCXlsAqNXdH9RSqLkgoRERGJCdVUiEilKk8RZ3kKQ0sruCyrGDNWon28fGh8JRWX+rcLfex7\n6PHCFZSW1bEz0kfIlzROeY9X0eNURpyhHWIr8nkkungV9FarpMLMxgDjgdbAUuAW59zC+EZVNfbs\n+T7eIcRMTToXgLVr3+fYY/vGO4yY2bJldszGKk8RZ3kKQ0sruCxtXSzPJbhLZySPlw8XX7jiUv9n\n9dBD+9myZX2Rx75DIatXL8esgJyc1LAFpaV17Pzxxz2sXr283I+QD1Xezp+RFpJmZmaSkZER9f6R\nxBm8zt8hNtrPozznEk/xLOitNpc/zOwq4HHgQaAHXlIx08xaxDWwKrJ37w/xDiFmatK5gJdU1CSx\n/EVcniLO8hSGllZwWdq6WJ5L8OPeI3m8fLj4whWX+j+rgoL0Io99r1u3f+B4mzdnlVhQWlrHTv+Y\n5X2EfEnjlNX5M9JC0szMzArtH0mcwesO/fyi+zzKcy7xFM+C3uo0UzEOeME5Nw3A7P+3d+9RV9V1\nHsffHy6DeE/LSyPmQkksjCmd0hTTsbRlkTI2auIyZbTBscnpMpWrGGdqapyazEtjf5SFl0odmzFZ\ng1KOshQQGS6pgRCKF5SroAgIiPCdP36/I5vjw8N5zjm42cfPa62zePb9e57Dc/Z3/36/vb8aDXwC\nGAV8r8zAzKx7jQzibGSdYmn3nixrp2bLyzca35Zy73u8Ybtevbb+yu6u9HxRbVBrT0vI12v0yZ+t\nlp5vdfvu4tz6CbGd1+1R1OrvsRmVaKmQ1Bc4Cvjf2ryICOBeYMfeFG9mZmYNqURSAbwd6A0srZu/\nlDS+okvr16/akTGZmZlZQZW6P7oiILqYvwvAihXjiVjPokVT2bhxNRs2vMSyZY9t9e9zz00G1rdl\nWTv3Vb9s8+aNOzT2N3NZ8b2UHUs7lr366iqee27qThFLO5a9+upq+vTZOWJpdVntvTTz99q/f3/W\nrn2GKVOmsHTpQjZu7N+2+JYsmUHfvlv2vWbNA6xb92JTn00tzokTJ7LPPvts9UW4cuXKrWKvHber\ndbtT28+aNQ8AbPd4vXtPY9Om7R9n2bJlTJgwoentexJncVntd93s76OR91KmVn+P8+fPr/24S0+P\nrdSLsHPL3R+vAGdGxF2F+WOBvSJiRN365wK/eFODNDMz6ywjI+KXPdmgEi0VEbFR0gzgZOAuAEnK\n09d2sckEYCTwNNB94QIzMzMr2gU4hHQu7ZFKtFQASDoLuBH4G2Aa6W6QTwODI2J5mbGZmZlZRVoq\nACLi9vxMim8B+wO/B051QmFmZrZzqExLhZmZme3cqnJLqZmZme3knFSYmZlZW3RkUiHpUklPSVon\naaqkPy87pmZIGibpLknPS9os6VNlx9QsSZdLmibpZUlLJf23pHeXHVezJI2W9IikVfk1RdLHy46r\nHfJntVnSVWXH0gxJV+T4i685ZcfVCknvlHSzpBckvZL/732g7Liakb+b6z+fzZKuKzu2npLUS9K3\nJS3In8sTkr5ZdlytkLS7pKslPZ3f0yRJRze6fcclFR1WeGw30oDUS+n6IV9VMgy4DvgQ8FGgL/Bb\nSf1Ljap5C4GvkR4ffxRwH/AbSUeUGlWLcgJ+Menvpsr+QBrQfUB+HV9uOM2TtDcwGdgAnAocAXwZ\neLHMuFpwNFs+lwOAj5G+324vM6gmfZ10R+LfAoOBrwJflfT5UqNqzQ2kxzWMBIYAvwPulXRgIxt3\n3EBNSVOBhyPisjwt0gng2oiobOExSZuBM4oP/6qynOQtA06IiEllx9MOklYAX4mIn5cdSzMk7Q7M\nAC4BxgCzIuJL5UbVc5KuAE6PiEpeydeTdCVwbER8pOxYdgRJVwOnRUTlWi4ljQOWRMTFhXl3AK9E\nxPnlRdYcSbsAq4HhEXFPYf50YHxE/OP29tFRLRUuPFYpe5OuTlaWHUirchPoOcCuwENlx9OC/wDG\nRcR9ZQfSBoNyt+GTkm6RNKDsgFowHJgu6fbcdThT0kVlB9UO+Tt7JOnquIqmACdLGgQgaShwHDC+\n1Kia14dUZ6u+tuk6Gmztq8xzKhrUXeGxw9/8cKwrufXoamBSRFS2r1vSEFISUcvuR0TE3HKjak5O\niv6M1DRddVOBC4B5wIHAPwEPSBoSETu+Nnr7DSS1Hv0A+A6pC/FaSesj4pZSI2vdCGAv0oMNq+hK\nYE9grqRNpAv1b0TEreWG1ZyIWCPpIWCMpLmkc+e5pIvy+d1unHVaUrEt2yo8ZuW4HngPKaOvsrnA\nUFKry5nATZJOqFpiIekgUpL3sYjYWHY8rYqI4qOF/yBpGvAMcBZQxa6pXsC0iBiTpx+R9F5SolH1\npGIUcHdELCk7kCadTTrpngPMISXm10haFBE3lxpZ884DfgY8D7wGzAR+CTTUndhpScULwCbSAK2i\n/Xhj64WVQNKPgNOAYRGxuOx4WhERrwEL8uRMSR8ELiN92VfJUcA7gBm5FQlSi98JecBZv6jw4KuI\nWCXpj8BhZcfSpMXA43XzHgf+soRY2kbSwaRB22eUHUsLvgd8NyL+M0/PlnQIcDlQyaQiIp4CTsqD\n6PeMiKWSbgWeamT7jhpTka+yaoXHgK0Kj00pKy5LckJxOnBSRDxbdjw7QC+gX9lBNOFe4EjSVdbQ\n/JpOugoeWuWEAl4fgHoo6eRcRZN5Y/ft4aTWlyobRbrYq+r4A0jjqOr/PjbTAefWiFiXE4q3ke46\nurOR7TqtpQLgKuDGXNW0VnhsV2BsmUE1Q9JupKur2tXjwDwQaGVELCwvsp6TdD3wGeBTwFpJtdak\nVRFRuUqykr4D3E26s2gP0mCzjwCnlBlXM/I4g63GtkhaC6yIiPor5J2epO8D40gn3T8F/pnUjPur\nMuNqwQ+ByZIuJ912+SHgItKtv5WUL/YuAMZGxOaSw2nFOOAbkhYCs0ldBF8EflpqVC2QdArpnDMP\nGERqjXmcBs+hHZdUdFjhsaOB+0mZcJAGakEa1DSqrKCaNJr0HibWzb8QuOlNj6Z1+5PiPhBYBTwK\nnNIhd05AtccgHUTqA94XWA5MAo6JiBWlRtWkiJguaQRpUOAYUjP0ZVUdDJh9FBhANce4FH0e+Dbp\nzqn9gEXAj/O8qtoL+FdSQr4SuAP4ZkRsamTjjntOhZmZmZWj8v0+ZmZmtnNwUmFmZmZt4aTCzMzM\n2sJJhZmZmbWFkwozMzNrCycVZmZm1hZOKszMzKwtnFSYmZlZWzipMLOWSLpf0lUlx9BX0nxJx7R5\nv/tKWirpne3cr1mnclJh1gEk/VzS5sLrBUl3SzqypHgOlfQzSc9IWi9poaTfSTpX0o743rkEWBAR\nUxuM71pJc7axbICkTZI+mR/tfSPpsf9mth1OKsw6x92kmiQHAH9BKqI17s0OIpeAn0mqpHkJ8F7g\nRFKRpdF5ut0upWdFnG4ADt9Gy8aFwBK2VM8cC4yUtHdLEZq9BTipMOscGyJieUQsi4hHgX8DBkja\nF0DSlZLmSVor6UlJ35LUu7axpCskzZJ0nqSnJL0k6Ve5Wm5tnV0l3SRptaTnJX2pizjGAnMj4riI\nGB8RT+bXbRFxQkQ8VthfozF9TtKzeb3bJO1RWOdoYCB1JbQlHZTXfTG33Nwp6V0AEfEIMIuuC/N9\nlkL1zIiYQyoUNaLBz8HsLctJhVkHkrQ7cB4wv1Cd82XgfOAI4Auk8tlfrNv0UOB04DTgE6Ry7l8v\nLP93YBgwnFTm/UTgqMJx3w8Mzus1opGYDgP+KsdzKvB+4PrC8uOBebmEey2OPsAEUgXZ4/JrNXBP\nXgapteIsSf0L250EHMIbq2dOy+/bzLrhpMKscwzPLQirSSfrTwLn1BZGxHcj4uGIeDYi/gf4AXBW\n3T4EfDYiHo+IycDNwMkAucViFPDliJgYEbNJV/W9C9sPIpVN/+PrO5TeUYsrv0b3MKZ+wPkR8VhE\nTAL+DjhH0n55+buAxXXbnE2qwvy5iJgTEfOAvwYOJiVCkMqj/wkpYam5AHgwIp6o29+ifBwz64aT\nCrPOcR/wPmAo8EHgt6Qr8wEAks6WNEnS4px4/AvpJFv0dES8UpheDNRO3ocCfUlX7QBExIvAvC5i\nicLPK3JMQ4GXSCdyehDTsxFRTBoeIiUyh+fp/sD6um2GAoOKyUyOo19+H0TEKuC/yF0guUvlTFIL\nRr11wK5dzDezgj7bX8XMKmJtRDyVf14g6SJS8//FksYDtwBjSMnGKuAzQP2YiI1108GWiw8V5m3L\n/LzeYOBRgDw2YQGApNdqK0o6tsGY6kXdvy8AQ+rW2R2YDpxbiLtmeeHnG4B7JQ0ktci8BtzRxTH3\nqdvOzLrglgqzzraZdCX/YVIrxJURMTMiniSNHeiJJ0gn3dfvmJD0NuDdtemImAXMBb4iqf5kXu/Y\nBmM6WNIBhekPA5vY0sUyi5TEFM0kdcUsj4gFda/VhXjvJyU8o0hdH7dGxLouYhiSj2Nm3XBSYdY5\n+knaP78GA9cBu5FuK51POjmfLWmgpC8AZ/Rk53kg5A3A9yWdJGkIaUDjprpVLyR1TUyWNFzSYZKO\nyGMp3l5Yv9GYNgA3SnqfpGHANcBtEbEsL78f2E3Sewrb/ILUgvEbScdLOkTSiZKu6eJBVmNJt74e\nQxddH3kg51GkgZ9m1g0nFWad4+OkAYWLgKmkE+GnI+KBiBgH/JCUaMwinUCbeaDTPwAPAneRuiwe\nBGYUV4iIh/Ox5wI/AmYDk0mDJ/8e+HFer9GY5pPGPowH7gF+T3ouRe14K4E7SXe71OatA04AngV+\nDcwBfkIaU/Fy3f7HAnsCsyPi/7o4/hnAMxExZRu/EzPLFNFd96iZWXkkXQGcHhEf2M56R5KSnMOK\nt5a2KYaHgKsj4rZ27tesE7mlwswqLz9Q62v0fJxIt/KDw37thMKsMb77w8w6QkTctAP2uYLGH+Rl\n9pbn7g8zMzNrC3d/mJmZWVs4qTAzM7O2cFJhZmZmbeGkwszMzNrCSYWZmZm1hZMKMzMzawsnFWZm\nZtYWTirMzMysLZxUmJmZWVv8P+lTo7X+4dupAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0ed0a9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import plotly.plotly as py\n",
    "bins = np.linspace(0, 9, 200)\n",
    "plt.hist(labels,bins,alpha=0.5)\n",
    "plt.title(\"Bandgap Histogram\")\n",
    "plt.xlabel(\"BandGap(eV)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.text(3, 45, \"mean of data is \"+str(np.around(np.mean(labels),decimals=2))+\" eV\")\n",
    "plt.text(3, 40, \"median of data is \"+str(np.around(np.median(labels),decimals=2))+\" eV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randamize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "# train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "# test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "# valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "# shuffle  the data\n",
    "Fulldata,labels=randomize(Fulldata,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save machine learning data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'MachineLearningData.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'Fulldata':Fulldata,\n",
    "    'labels':labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load machine learning data to pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'MachineLearningData.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  Fulldata = save['Fulldata']\n",
    "  labels = save['labels']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine learning\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of always guessing the average band gap is: 1.081 eV\n"
     ]
    }
   ],
   "source": [
    "baselineError = mean(abs(mean(train_labels) - train_labels))\n",
    "print(\"The MAE of always guessing the average band gap is: \" + str(round(baselineError, 3)) + \" eV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the linear ridge regression band gap model using the naive feature set is: 0.683 eV\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAF5CAYAAADUL/MIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0ee965610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train linear ridge regression model using naive feature set\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import linear_model, cross_validation, metrics, ensemble\n",
    "\n",
    "train_dataset=Fulldata[0:1300]\n",
    "train_labels=labels[0:1300]\n",
    "test_dataset=Fulldata[1300:1531]\n",
    "test_labels=labels[1300:1531]\n",
    "\n",
    "num_samples=train_dataset.shape[0]\n",
    "#this won't work if num_samples are too small, if num_samples is too small, all Y is 0( the first number type), so it has to be large engouh\n",
    "(samples, width, height) = train_dataset.shape\n",
    "X = np.reshape(train_dataset,(samples,width*height))[0:num_samples]\n",
    "Y = train_labels[0:num_samples]\n",
    "\n",
    "#alpha is a tuning parameter affecting how regression deals with collinear inputs\n",
    "linear = linear_model.Ridge(alpha = 0.6)  \n",
    "\n",
    "cv = cross_validation.ShuffleSplit(len(Y),n_iter=10, test_size=0.1, random_state=0)\n",
    "\n",
    "scores = cross_validation.cross_val_score(linear, X,Y, cv=cv, scoring='mean_absolute_error')\n",
    "\n",
    "print(\"The MAE of the linear ridge regression band gap model using the naive feature set is: \"+ str(round(abs(mean(scores)), 3)) + \" eV\")\n",
    "############# plot it##########################################\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(linear, X, Y, cv=10)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y, predicted)\n",
    "ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=2)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "### without hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (1100, 162), (1100, 1))\n",
      "('Validation set', (200, 162), (200, 1))\n",
      "('Test set', (230, 162), (230, 1))\n"
     ]
    }
   ],
   "source": [
    "# image_size = 28\n",
    "num_labels = 1\n",
    "train_end=1100\n",
    "valid_end=1300\n",
    "train_dataset=Fulldata[0:train_end]\n",
    "train_labels=labels[0:train_end]\n",
    "valid_dataset=Fulldata[train_end:valid_end]\n",
    "valid_labels=labels[train_end:valid_end]\n",
    "test_dataset=Fulldata[valid_end:1531]\n",
    "test_labels=labels[valid_end:1531]\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, Fulldata.shape[1] * Fulldata.shape[2])).astype(np.float32)\n",
    "  labels = (labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 1.883463\n",
      "Validation Loss: 1.584549\n",
      "Loss at step 10000: 0.636692\n",
      "Validation Loss: 0.687881\n",
      "Loss at step 20000: 0.631331\n",
      "Validation Loss: 0.686636\n",
      "Loss at step 30000: 0.629745\n",
      "Validation Loss: 0.683074\n",
      "Loss at step 40000: 0.629499\n",
      "Validation Loss: 0.682205\n",
      "Test Loss: 0.664910\n"
     ]
    }
   ],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "\n",
    "train_subset = train_end\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  weights = tf.Variable(tf.truncated_normal([Fulldata.shape[1] * Fulldata.shape[2], num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = logits  \n",
    "\n",
    "  valid_prediction = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  test_prediction = tf.matmul(tf_test_dataset, weights) + biases\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 50000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 10000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with one hidden layer, train with batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 9.913927\n",
      "Validation Loss: 28.716265\n",
      "Loss at step 1000: 0.553740\n",
      "Validation Loss: 0.936711\n",
      "Loss at step 2000: 0.622823\n",
      "Validation Loss: 0.750750\n",
      "Loss at step 3000: 0.440426\n",
      "Validation Loss: 0.861358\n",
      "Loss at step 4000: 0.458674\n",
      "Validation Loss: 0.795093\n",
      "Loss at step 5000: 0.436431\n",
      "Validation Loss: 0.765197\n",
      "Loss at step 6000: 0.478887\n",
      "Validation Loss: 0.790238\n",
      "Loss at step 7000: 0.420878\n",
      "Validation Loss: 0.786454\n",
      "Loss at step 8000: 0.320174\n",
      "Validation Loss: 0.656050\n",
      "Loss at step 9000: 0.290202\n",
      "Validation Loss: 0.717809\n",
      "Test Loss: 0.690147\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "train_subset = train_end\n",
    "batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] * Fulldata.shape[2], num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = logits  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add regulation to previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 75.267990\n",
      "Validation Loss: 17.111399\n",
      "Loss at step 10000: 0.614537\n",
      "Validation Loss: 0.646773\n",
      "Loss at step 20000: 0.731811\n",
      "Validation Loss: 0.788381\n",
      "Loss at step 30000: 0.672801\n",
      "Validation Loss: 0.639590\n",
      "Loss at step 40000: 0.649371\n",
      "Validation Loss: 0.679590\n",
      "Loss at step 50000: 0.613999\n",
      "Validation Loss: 0.703059\n",
      "Loss at step 60000: 0.612504\n",
      "Validation Loss: 0.822633\n",
      "Loss at step 70000: 0.581319\n",
      "Validation Loss: 0.941529\n",
      "Loss at step 80000: 0.696750\n",
      "Validation Loss: 0.687981\n",
      "Loss at step 90000: 0.505735\n",
      "Validation Loss: 0.599858\n",
      "Test Loss: 0.608422\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] * Fulldata.shape[2], num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  train_prediction = logits  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 100000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 10000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout added to previous test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 73.645538\n",
      "Validation Loss: 16.276495\n",
      "Loss at step 1000: 24.098148\n",
      "Validation Loss: 0.686216\n",
      "Loss at step 2000: 9.174386\n",
      "Validation Loss: 0.799104\n",
      "Loss at step 3000: 3.764966\n",
      "Validation Loss: 0.740538\n",
      "Loss at step 4000: 1.878308\n",
      "Validation Loss: 0.751335\n",
      "Loss at step 5000: 1.016863\n",
      "Validation Loss: 0.606579\n",
      "Loss at step 6000: 0.864439\n",
      "Validation Loss: 0.675523\n",
      "Loss at step 7000: 0.684641\n",
      "Validation Loss: 0.720152\n",
      "Loss at step 8000: 0.670896\n",
      "Validation Loss: 0.604405\n",
      "Loss at step 9000: 0.830222\n",
      "Validation Loss: 0.630259\n",
      "Test Loss: 0.617904\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "#batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([Fulldata.shape[1] * Fulldata.shape[2], num_hidden_nodes]))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################\n",
    "  layer_1_train= tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  train_prediction = tf.matmul(layer_1_train, weights_2) + biases_2  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below try to use different initial value(stddev) for weight to see if accuracy can be improved,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 2.629410\n",
      "Validation Loss: 1.136134\n",
      "Loss at step 1000: 0.861606\n",
      "Validation Loss: 0.610521\n",
      "Loss at step 2000: 0.632770\n",
      "Validation Loss: 0.590188\n",
      "Loss at step 3000: 0.758573\n",
      "Validation Loss: 0.798777\n",
      "Loss at step 4000: 0.566694\n",
      "Validation Loss: 0.672346\n",
      "Loss at step 5000: 0.764544\n",
      "Validation Loss: 0.646416\n",
      "Loss at step 6000: 0.625068\n",
      "Validation Loss: 0.651513\n",
      "Loss at step 7000: 0.557081\n",
      "Validation Loss: 0.697748\n",
      "Loss at step 8000: 0.716716\n",
      "Validation Loss: 0.643046\n",
      "Loss at step 9000: 0.632172\n",
      "Validation Loss: 0.770132\n",
      "Test Loss: 0.592279\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] * Fulldata.shape[2]\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  weights_2 =  tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train= tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  train_prediction = tf.matmul(layer_1_train, weights_2) + biases_2  \n",
    "\n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.matmul(layer_1_valid, weights_2) + biases_2\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.matmul(layer_1_test, weights_2) + biases_2\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "  #########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 3.012572\n",
      "Validation Loss: 1.219993\n",
      "Loss at step 1000: 1.336445\n",
      "Validation Loss: 0.676098\n",
      "Loss at step 2000: 0.722857\n",
      "Validation Loss: 0.620634\n",
      "Loss at step 3000: 0.687559\n",
      "Validation Loss: 0.838706\n",
      "Loss at step 4000: 0.692196\n",
      "Validation Loss: 0.794821\n",
      "Loss at step 5000: 0.641662\n",
      "Validation Loss: 0.638895\n",
      "Loss at step 6000: 0.577204\n",
      "Validation Loss: 0.600673\n",
      "Loss at step 7000: 0.513539\n",
      "Validation Loss: 0.635314\n",
      "Loss at step 8000: 0.535798\n",
      "Validation Loss: 0.608696\n",
      "Loss at step 9000: 0.689680\n",
      "Validation Loss: 0.715434\n",
      "Test Loss: 0.863027\n"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "num_hidden_nodes2=512\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] * Fulldata.shape[2]\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2=tf.Variable(tf.truncated_normal([num_hidden_nodes, num_hidden_nodes2],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_2=tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "  \n",
    "  weights_o =  tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes))))  \n",
    "  biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  layer_2=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_1,weights_2)+biases_2),0.75)\n",
    "  \n",
    "  logits = tf.matmul(layer_2, weights_o) + biases_o\n",
    "  \n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))+beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_o)+tf.nn.l2_loss(weights_2))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train=tf.nn.relu(tf.matmul(tf_train_dataset,weights_1)+biases_1)\n",
    "  layer_2_train=tf.nn.relu(tf.matmul(layer_1_train,weights_2)+biases_2)\n",
    "  train_prediction = tf.matmul(layer_2_train, weights_o) + biases_o  \n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  layer_2_valid = tf.nn.relu(tf.matmul(layer_1_valid, weights_2) + biases_2)  \n",
    "  valid_prediction = tf.matmul(layer_2_valid, weights_o) + biases_o\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  layer_2_test = tf.nn.relu(tf.matmul(layer_1_test, weights_2) + biases_2)\n",
    "  test_prediction = tf.matmul(layer_2_test, weights_o) + biases_o\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 10000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result here is not good due to small number of steps, a larger training step test is done at WSU grid which yields a big score at test loss of 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eb8ac7c27f8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# batch_size = train_subset/10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum_hidden_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_end' is not defined"
     ]
    }
   ],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "num_hidden_nodes2=512\n",
    "num_hidden_nodes3=128\n",
    "\n",
    "# so far 1e-3 yields best result 0.599\n",
    "beta=1e-3\n",
    "\n",
    "train_subset = train_end\n",
    "# batch_size = train_subset/10\n",
    "num_hidden_nodes = 1024\n",
    "# label dimention is 1\n",
    "num_labels=1\n",
    "import tensorflow as tf\n",
    "from tensorflow import contrib\n",
    "graph = tf.Graph()\n",
    "dimentions=Fulldata.shape[1] * Fulldata.shape[2]\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, 162))  \n",
    "  #tf_train_dataset = tf.constant(train_dataset[:batch_size, :])\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "  #tf_train_labels = tf.constant(train_labels[:batch_size])\n",
    "\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([dimentions, num_hidden_nodes],\n",
    "                                              stddev=math.sqrt(2.0/dimentions)))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2=tf.Variable(tf.truncated_normal([num_hidden_nodes, num_hidden_nodes2],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes))))\n",
    "  biases_2=tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    \n",
    "  weights_3=tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3],\n",
    "                                             stddev=math.sqrt(2.0/(num_hidden_nodes2))))\n",
    "  biases_3=tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    \n",
    "  \n",
    "  weights_o =  tf.Variable(tf.truncated_normal([num_hidden_nodes3, num_labels],\n",
    "                                               stddev=math.sqrt(2.0/(num_hidden_nodes3))))  \n",
    "  biases_o = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  layer_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1),keep_prob=0.8)\n",
    "  layer_2=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_1,weights_2)+biases_2),keep_prob=0.8)\n",
    "  layer_3=tf.nn.dropout(tf.nn.relu(tf.matmul(layer_2,weights_3)+biases_3),keep_prob=0.8)\n",
    "  \n",
    "  logits = tf.matmul(layer_3, weights_o) + biases_o\n",
    "  \n",
    "  loss = tf.reduce_mean(tf.abs(logits-tf_train_labels))\n",
    "  +beta*(tf.nn.l2_loss(weights_1)+tf.nn.l2_loss(weights_o)\n",
    "  +tf.nn.l2_loss(weights_2)+tf.nn.l2_loss(weights_3))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#########################################################################################  \n",
    "  layer_1_train=tf.nn.relu(tf.matmul(tf_train_dataset,weights_1)+biases_1)\n",
    "  layer_2_train=tf.nn.relu(tf.matmul(layer_1_train,weights_2)+biases_2)\n",
    "  layer_3_train=tf.nn.relu(tf.matmul(layer_2_train,weights_3)+biases_3)\n",
    "  train_prediction = tf.matmul(layer_3_train, weights_o) + biases_o\n",
    "\n",
    "#########################################################################################    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_valid_labels = tf.constant(valid_labels)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_test_labels = tf.constant(test_labels)\n",
    "\n",
    "  layer_1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  layer_2_valid = tf.nn.relu(tf.matmul(layer_1_valid, weights_2) + biases_2)\n",
    "  layer_3_valid = tf.nn.relu(tf.matmul(layer_2_valid, weights_3) + biases_3)\n",
    "  valid_prediction = tf.matmul(layer_3_valid, weights_o) + biases_o\n",
    "  valid_loss = tf.reduce_mean(tf.abs(valid_prediction-tf_valid_labels))\n",
    "    \n",
    "  layer_1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  layer_2_test = tf.nn.relu(tf.matmul(layer_1_test, weights_2) + biases_2)\n",
    "  layer_3_test = tf.nn.relu(tf.matmul(layer_2_test, weights_3) + biases_3)\n",
    "  test_prediction = tf.matmul(layer_2_test, weights_o) + biases_o\n",
    "  test_loss = tf.reduce_mean(tf.abs(test_prediction-tf_test_labels))\n",
    "#########################################################################################3\n",
    "num_steps = 1000\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    #_, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Validation Loss: %f' % valid_loss.eval())\n",
    "  print('Test Loss: %f' %  test_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
